[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nadifa Hossain",
    "section": "",
    "text": "About Me:\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Karlan & List 2007 Data Description\n\n\n\n\nNadifa Hossain\nJun 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning Applications in Marketing\n\n\n\n\nNadifa Hossain\nJun 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Model\n\n\n\n\nNadifa Hossain\nJun 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\nNadifa Hossain\nJun 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html",
    "href": "projects/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo explore how different “price” signals affect charitable giving, Dean Karlan and John List conducted a large-scale natural field experiment involving over 50,000 prior donors to a U.S.-based liberal nonprofit. The experiment aimed to test whether and how matching grant offers—a common fundraising tactic—alter donor behavior.\nParticipants were randomly assigned to receive one of several different types of fundraising letters. The control group received a standard letter without any mention of a matching grant. The treatment group received a letter with an announcement that a “concerned fellow member” would match their donation. Within the treatment group, further randomization varied three key features:\nMatching ratio: The letters promised either a $1:$1, $2:$1, or $3:$1 match.\nMaximum match amount: The match was capped at either $25,000, $50,000, $100,000, or left unstated.\nSuggested donation amounts: Each participant saw one of three ask amounts—equal to, 1.25×, or 1.5× their highest previous donation.\nThis design allowed the researchers to test both main effects and interaction effects of price (via match ratio), perceived value (via cap), and anchoring (via ask amounts).\nKey Findings:\n\nThe presence of a matching grant increased both the response rate (probability of donating) and the average donation.\nMerely including a match offer increased revenue per solicitation by 19% and the response rate by 22%.\nSurprisingly, higher match ratios ($2:$1 or $3:$1) did not produce better results than the $1:$1 ratio.\nGeographic political context mattered: Donors in “red states” (those that voted for George W. Bush in 2004) were significantly more responsive to the match offer than those in “blue states.”\nNo significant differences were found across different match cap amounts or suggested donation levels.\n\nThis study, published in the American Economic Review (2007), is notable for being one of the first real-world randomized trials testing economic theories of charitable giving on the “demand side”—how donor behavior responds to perceived price changes, framing effects, and social signals in a natural setting.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#introduction",
    "href": "projects/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo explore how different “price” signals affect charitable giving, Dean Karlan and John List conducted a large-scale natural field experiment involving over 50,000 prior donors to a U.S.-based liberal nonprofit. The experiment aimed to test whether and how matching grant offers—a common fundraising tactic—alter donor behavior.\nParticipants were randomly assigned to receive one of several different types of fundraising letters. The control group received a standard letter without any mention of a matching grant. The treatment group received a letter with an announcement that a “concerned fellow member” would match their donation. Within the treatment group, further randomization varied three key features:\nMatching ratio: The letters promised either a $1:$1, $2:$1, or $3:$1 match.\nMaximum match amount: The match was capped at either $25,000, $50,000, $100,000, or left unstated.\nSuggested donation amounts: Each participant saw one of three ask amounts—equal to, 1.25×, or 1.5× their highest previous donation.\nThis design allowed the researchers to test both main effects and interaction effects of price (via match ratio), perceived value (via cap), and anchoring (via ask amounts).\nKey Findings:\n\nThe presence of a matching grant increased both the response rate (probability of donating) and the average donation.\nMerely including a match offer increased revenue per solicitation by 19% and the response rate by 22%.\nSurprisingly, higher match ratios ($2:$1 or $3:$1) did not produce better results than the $1:$1 ratio.\nGeographic political context mattered: Donors in “red states” (those that voted for George W. Bush in 2004) were significantly more responsive to the match offer than those in “blue states.”\nNo significant differences were found across different match cap amounts or suggested donation levels.\n\nThis study, published in the American Economic Review (2007), is notable for being one of the first real-world randomized trials testing economic theories of charitable giving on the “demand side”—how donor behavior responds to perceived price changes, framing effects, and social signals in a natural setting.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#data",
    "href": "projects/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\ntitle: “Karlan & List 2007 Data Description” format: html execute: echo: true warning: false message: false —"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#experimental-results",
    "href": "projects/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nWe investigate whether being offered a matching grant (treatment) increased the likelihood of making a donation.\nWe’ll: - Visualize donation rates by group - Perform a Welch’s t-test and a linear regression - Run a probit regression to match results in Table 3, Column 1\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.stats import t\n\n# --- Barplot: proportion who donated by treatment group ---\ndonation_rates = df.groupby('treatment')['gave'].mean()\n\nplt.figure(figsize=(10, 6))\nplt.bar(['Control', 'Treatment'], donation_rates.values)\nplt.title('Proportion of People Who Donated by Group')\nplt.ylabel('Proportion Donated')\nplt.ylim(0, 0.03)\nplt.grid(axis='y')\nplt.show()\n\n# --- Welch's t-test manually ---\ntreat = df[df['treatment'] == 1]['gave']\ncontrol = df[df['treatment'] == 0]['gave']\n\nx1, x2 = treat.mean(), control.mean()\ns1, s2 = treat.std(ddof=1), control.std(ddof=1)\nn1, n2 = len(treat), len(control)\n\nse = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se\ndf_num = (s1**2 / n1 + s2**2 / n2)**2\ndf_denom = ((s1**2 / n1)**2 / (n1 - 1)) + ((s2**2 / n2)**2 / (n2 - 1))\ndf_welch = df_num / df_denom\np_val_t = 2 * t.sf(np.abs(t_stat), df_welch)\n\n# --- Linear regression ---\nlm = smf.ols('gave ~ treatment', data=df).fit()\n\n# --- Probit regression ---\nprobit = smf.probit('gave ~ treatment', data=df).fit(disp=0)\n\n# --- Output summary ---\nprint(\"=== Barplot: Proportion Donated ===\")\nprint(donation_rates)\n\nprint(\"\\n=== Welch’s t-test ===\")\nprint(f\"t-statistic = {t_stat:.3f}, p-value = {p_val_t:.4f}\")\n\nprint(\"\\n=== Linear Regression ===\")\nprint(lm.summary())\n\nprint(\"\\n=== Probit Regression ===\")\nprint(probit.summary())\n\n\n\n\n\n\n\n\n=== Barplot: Proportion Donated ===\ntreatment\n0    0.017858\n1    0.022039\nName: gave, dtype: float64\n\n=== Welch’s t-test ===\nt-statistic = 3.209, p-value = 0.0013\n\n=== Linear Regression ===\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        16:11:57   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n=== Probit Regression ===\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        16:11:57   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom scipy.stats import ttest_ind\n\n# Keep only treated individuals for ratio comparisons\ndf_treat = df[df['treatment'] == 1].copy()\n\n# Create ratio1 dummy (1 if 1:1 match ratio)\ndf_treat['ratio1'] = (df_treat['ratio'] == \"1\").astype(int)\n\n# --- T-tests: comparing response rates between ratio levels ---\ndef ttest_response(var1, var2, label1, label2):\n    g1 = df_treat[df_treat[var1] == 1]['gave']\n    g2 = df_treat[df_treat[var2] == 1]['gave']\n    t_stat, p_val = ttest_ind(g1, g2, equal_var=False)\n    print(f\"T-test: {label1} vs {label2} | t = {t_stat:.3f}, p = {p_val:.4f}\")\n\n# Run t-tests between match ratios\nttest_response('ratio1', 'ratio2', '1:1', '2:1')\nttest_response('ratio2', 'ratio3', '2:1', '3:1')\nttest_response('ratio1', 'ratio3', '1:1', '3:1')\n\n# --- Regression: gave ~ ratio1 + ratio2 + ratio3 (1:1 is omitted baseline) ---\nreg1 = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_treat).fit()\n\n# --- Alternatively: use categorical variable for ratio ---\nreg2 = smf.ols(\"gave ~ C(ratio)\", data=df_treat).fit()\n\n# --- Print regression summaries ---\nprint(\"\\nRegression with dummy variables (1:1 omitted):\")\nprint(reg1.summary())\n\nprint(\"\\nRegression with categorical ratio variable:\")\nprint(reg2.summary())\n\n# --- Response rate differences from raw data ---\nrate_1_1 = df_treat[df_treat['ratio'] == \"1\"]['gave'].mean()\nrate_2_1 = df_treat[df_treat['ratio'] == \"2\"]['gave'].mean()\nrate_3_1 = df_treat[df_treat['ratio'] == \"3\"]['gave'].mean()\n\ndiff_2_1_vs_1_1 = rate_2_1 - rate_1_1\ndiff_3_1_vs_2_1 = rate_3_1 - rate_2_1\n\nprint(f\"\\nResponse Rate Differences from Data:\")\nprint(f\"2:1 - 1:1 = {diff_2_1_vs_1_1:.4f}\")\nprint(f\"3:1 - 2:1 = {diff_3_1_vs_2_1:.4f}\")\n\n# --- Compare to regression coefficients ---\ncoef_2_1 = reg1.params['ratio2']\ncoef_3_1 = reg1.params['ratio3']\ndiff_coef_3_1_vs_2_1 = coef_3_1 - coef_2_1\n\nprint(f\"\\nResponse Rate Differences from Regression Coefficients:\")\nprint(f\"2:1 - 1:1 = {coef_2_1:.4f}\")\nprint(f\"3:1 - 2:1 = {diff_coef_3_1_vs_2_1:.4f}\")\n\nT-test: 1:1 vs 2:1 | t = nan, p = nan\nT-test: 2:1 vs 3:1 | t = -0.050, p = 0.9600\nT-test: 1:1 vs 3:1 | t = nan, p = nan\n\nRegression with dummy variables (1:1 omitted):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.524\nTime:                        16:11:57   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nRegression with categorical ratio variable:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.4263\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.734\nTime:                        16:11:57   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33392   BIC:                        -3.333e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept       1.23e+09   1.12e+10      0.110      0.912   -2.07e+10    2.32e+10\nC(ratio)[T.1]  -1.23e+09   1.12e+10     -0.110      0.912   -2.32e+10    2.07e+10\nC(ratio)[T.2]  -1.23e+09   1.12e+10     -0.110      0.912   -2.32e+10    2.07e+10\nC(ratio)[T.3]  -1.23e+09   1.12e+10     -0.110      0.912   -2.32e+10    2.07e+10\n==============================================================================\nOmnibus:                    38963.855   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506451.717\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                     3.22e+13\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 4.31e-23. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\nResponse Rate Differences from Data:\n2:1 - 1:1 = nan\n3:1 - 2:1 = nan\n\nResponse Rate Differences from Regression Coefficients:\n2:1 - 1:1 = 0.0019\n3:1 - 2:1 = 0.0001\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nWe explore whether being offered a matching grant affects: 1. How much people donate on average (unconditionally) 2. How much people donate among those who do give (conditionally) 3. The distribution of donations with annotated averages\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\n\n# --- Unconditional regression (all people) ---\nmodel_uncond = smf.ols(\"amount ~ treatment\", data=df).fit()\nprint(\"Unconditional OLS regression (donation amount on treatment):\")\nprint(model_uncond.summary())\n\n# --- Conditional regression (only among donors) ---\ndf_donors = df[df['gave'] == 1]\nmodel_cond = smf.ols(\"amount ~ treatment\", data=df_donors).fit()\nprint(\"\\nConditional OLS regression (amount | gave == 1):\")\nprint(model_cond.summary())\n\n# --- Interpretation prompt ---\nprint(\"\\nInterpretation:\")\nprint(\"- The unconditional regression includes everyone and reflects both intensive (amount) and extensive (whether they donated) margins.\")\nprint(\"- The conditional regression isolates only the intensive margin — how much donors gave once they decided to give.\")\nprint(\"- The treatment coefficient in the conditional regression does NOT have a direct causal interpretation; it's conditional on post-treatment behavior.\")\n\n# --- Histograms of donation amounts among donors, by treatment ---\ntreat_donors = df_donors[df_donors['treatment'] == 1]['amount']\ncontrol_donors = df_donors[df_donors['treatment'] == 0]['amount']\n\nplt.figure(figsize=(14, 6))\n\n# Control group\nplt.subplot(1, 2, 1)\nplt.hist(control_donors, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\nplt.axvline(control_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group: Donation Amounts (Among Donors)')\nplt.xlabel('Amount Donated')\nplt.ylabel('Frequency')\nplt.text(control_donors.mean(), plt.ylim()[1]*0.9, f\"Mean: {control_donors.mean():.2f}\", color='red')\n\n# Treatment group\nplt.subplot(1, 2, 2)\nplt.hist(treat_donors, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.axvline(treat_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group: Donation Amounts (Among Donors)')\nplt.xlabel('Amount Donated')\nplt.ylabel('Frequency')\nplt.text(treat_donors.mean(), plt.ylim()[1]*0.9, f\"Mean: {treat_donors.mean():.2f}\", color='red')\n\nplt.tight_layout()\nplt.show()\n\nUnconditional OLS regression (donation amount on treatment):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        16:11:57   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nConditional OLS regression (amount | gave == 1):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        16:11:57   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nInterpretation:\n- The unconditional regression includes everyone and reflects both intensive (amount) and extensive (whether they donated) margins.\n- The conditional regression isolates only the intensive margin — how much donors gave once they decided to give.\n- The treatment coefficient in the conditional regression does NOT have a direct causal interpretation; it's conditional on post-treatment behavior."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#simulation-experiment",
    "href": "projects/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nTo simulate the intuition behind comparing group means, we draw: - 100,000 samples from the control group donation distribution - 10,000 samples from the treatment group We compute the difference between paired samples and plot the cumulative average of the differences.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Use unconditional donation amount distributions\ncontrol_dist = df[df['treatment'] == 0]['amount']\ntreatment_dist = df[df['treatment'] == 1]['amount']\n\n# Simulate draws\nnp.random.seed(42)\nsim_control = np.random.choice(control_dist, size=100000, replace=True)\nsim_treat = np.random.choice(treatment_dist, size=10000, replace=True)\n\n# Match lengths for subtraction (repeat treatment sample)\nsim_treat_matched = np.tile(sim_treat, 10)  # Now length = 100000\n\n# Compute vector of differences\ndiffs = sim_treat_matched - sim_control\n\n# Compute cumulative average\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# True difference in means\ntrue_diff = treatment_dist.mean() - control_dist.mean()\n\n# Plot\nplt.figure(figsize=(12, 6))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences')\nplt.axhline(true_diff, color='red', linestyle='--', linewidth=2, label='True Mean Difference')\nplt.xlabel('Number of Samples')\nplt.ylabel('Cumulative Average (Treatment - Control)')\nplt.title('Simulated Cumulative Average of Donation Differences')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Display true difference for interpretation\nprint(f\"\\nTrue difference in average donation amount (treatment - control): {true_diff:.4f}\")\n\n\n\n\n\n\n\n\n\nTrue difference in average donation amount (treatment - control): 0.1536\n\n\n\n\nCentral Limit Theorem\nWe simulate 1000 experiments at each sample size (50, 200, 500, 1000). Each experiment: - Takes independent samples from control and treatment donation distributions - Computes the mean difference in donations We then plot histograms of these mean differences and observe whether zero falls near the center or in the tails.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Extract full distributions\ncontrol = df[df['treatment'] == 0]['amount'].values\ntreatment = df[df['treatment'] == 1]['amount'].values\n\n# Sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# Prepare for plots\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\naxs = axs.flatten()\n\n# Run simulation and plotting loop\nnp.random.seed(123)\nfor i, n in enumerate(sample_sizes):\n    diff_means = []\n    for _ in range(n_simulations):\n        sample_control = np.random.choice(control, n, replace=True)\n        sample_treatment = np.random.choice(treatment, n, replace=True)\n        diff_means.append(sample_treatment.mean() - sample_control.mean())\n    \n    axs[i].hist(diff_means, bins=30, color='skyblue', edgecolor='black')\n    axs[i].axvline(0, color='red', linestyle='--', linewidth=2, label=\"Zero\")\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Average Difference (Treatment - Control)\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.suptitle(\"Distributions of Average Differences from 1000 Simulated Experiments\")\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#load-and-describe-dataset",
    "href": "projects/HW1/hw1_questions.html#load-and-describe-dataset",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Load and Describe Dataset",
    "text": "Load and Describe Dataset\n\nimport pandas as pd\n\n# Load the dataset\ndata_path = \"karlan_list_2007.dta\"\ndf = pd.read_stata(data_path)\n\n# Identify variable types\nnumerical_vars = df.select_dtypes(include=['number']).columns.tolist()\ncategorical_vars = df.select_dtypes(include=['category']).columns.tolist()\n\n# Summary statistics for numerical variables\nsummary_stats = df.describe()\n\n# Display variable types and summary\nprint(\"Numerical Variables:\")\nfor var in numerical_vars:\n    print(f\" - {var}\")\n\nprint(\"\\nCategorical Variables:\")\nfor var in categorical_vars:\n    print(f\" - {var}\")\n\nprint(\"\\nSummary Statistics for Numerical Variables:\")\nprint(summary_stats)\n\nNumerical Variables:\n - treatment\n - control\n - ratio2\n - ratio3\n - size25\n - size50\n - size100\n - sizeno\n - askd1\n - askd2\n - askd3\n - ask1\n - ask2\n - ask3\n - amount\n - gave\n - amountchange\n - hpa\n - ltmedmra\n - freq\n - years\n - year5\n - mrm2\n - dormant\n - female\n - couple\n - state50one\n - nonlit\n - cases\n - statecnt\n - stateresponse\n - stateresponset\n - stateresponsec\n - stateresponsetminc\n - perbush\n - close25\n - red0\n - blue0\n - redcty\n - bluecty\n - pwhite\n - pblack\n - page18_39\n - ave_hh_sz\n - median_hhincome\n - powner\n - psch_atlstba\n - pop_propurban\n\nCategorical Variables:\n - ratio\n - size\n - ask\n\nSummary Statistics for Numerical Variables:\n          treatment       control        ratio2        ratio3        size25  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.666813      0.333187      0.222311      0.222211      0.166723   \nstd        0.471357      0.471357      0.415803      0.415736      0.372732   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n75%        1.000000      1.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n             size50       size100        sizeno         askd1         askd2  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.166623      0.166723      0.166743      0.222311      0.222291   \nstd        0.372643      0.372732      0.372750      0.415803      0.415790   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n       ...        redcty       bluecty        pwhite        pblack  \\\ncount  ...  49978.000000  49978.000000  48217.000000  48047.000000   \nmean   ...      0.510245      0.488715      0.819599      0.086710   \nstd    ...      0.499900      0.499878      0.168560      0.135868   \nmin    ...      0.000000      0.000000      0.009418      0.000000   \n25%    ...      0.000000      0.000000      0.755845      0.014729   \n50%    ...      1.000000      0.000000      0.872797      0.036554   \n75%    ...      1.000000      1.000000      0.938827      0.090882   \nmax    ...      1.000000      1.000000      1.000000      0.989622   \n\n          page18_39     ave_hh_sz  median_hhincome        powner  \\\ncount  48217.000000  48221.000000     48209.000000  48214.000000   \nmean       0.321694      2.429012     54815.700533      0.669418   \nstd        0.103039      0.378105     22027.316665      0.193405   \nmin        0.000000      0.000000      5000.000000      0.000000   \n25%        0.258311      2.210000     39181.000000      0.560222   \n50%        0.305534      2.440000     50673.000000      0.712296   \n75%        0.369132      2.660000     66005.000000      0.816798   \nmax        0.997544      5.270000    200001.000000      1.000000   \n\n       psch_atlstba  pop_propurban  \ncount  48215.000000   48217.000000  \nmean       0.391661       0.871968  \nstd        0.186599       0.258633  \nmin        0.000000       0.000000  \n25%        0.235647       0.884929  \n50%        0.373744       1.000000  \n75%        0.530036       1.000000  \nmax        1.000000       1.000000  \n\n[8 rows x 48 columns]\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nIn this section, we check if the variable mrm2 (months since last donation) is balanced across treatment and control groups. We do this using:\n\nA Welch’s t-test using the formula from class\nA linear regression of mrm2 on treatment\n\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\n# Filter for valid mrm2 values\ndf_mrm2 = df[['mrm2', 'treatment']].dropna()\n\n# Split groups\ntreat = df_mrm2[df_mrm2['treatment'] == 1]['mrm2']\ncontrol = df_mrm2[df_mrm2['treatment'] == 0]['mrm2']\n\n# Sample statistics\nx1, x2 = treat.mean(), control.mean()\ns1, s2 = treat.std(ddof=1), control.std(ddof=1)\nn1, n2 = len(treat), len(control)\n\n# Welch's t-test manually (from slide 37)\nse_diff = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se_diff\n\n# Degrees of freedom (Welch–Satterthwaite)\ndf_num = (s1**2 / n1 + s2**2 / n2)**2\ndf_denom = ((s1**2 / n1)**2 / (n1 - 1)) + ((s2**2 / n2)**2 / (n2 - 1))\ndf_welch = df_num / df_denom\n\n# Two-sided p-value\np_val_ttest = 2 * stats.t.sf(np.abs(t_stat), df_welch)\n\n# Linear regression\nmodel = smf.ols('mrm2 ~ treatment', data=df_mrm2).fit()\n\n# Show results\nprint(f\"Welch's t-statistic: {t_stat:.3f}\")\nprint(f\"Welch's p-value: {p_val_ttest:.3f}\")\nprint(f\"Regression coefficient (treatment effect): {model.params['treatment']:.3f}\")\nprint(f\"Regression t-statistic: {model.tvalues['treatment']:.3f}\")\nprint(f\"Regression p-value: {model.pvalues['treatment']:.3f}\")\n\nWelch's t-statistic: 0.120\nWelch's p-value: 0.905\nRegression coefficient (treatment effect): 0.014\nRegression t-statistic: 0.119\nRegression p-value: 0.905"
  },
  {
    "objectID": "hw1.html",
    "href": "hw1.html",
    "title": "Nadifa's Awesome Work",
    "section": "",
    "text": "import pandas as pd\n\n# Load the dataset\ndata_path = \"karlan_list_2007.dta\"\ndf = pd.read_stata(data_path)\n\n# Dictionary of variable descriptions\ndescriptions = {\n    \"treatment\": \"Treatment\",\n    \"control\": \"Control\",\n    \"ratio\": \"Match ratio\",\n    \"ratio2\": \"2:1 match ratio\",\n    \"ratio3\": \"3:1 match ratio\",\n    \"size\": \"Match threshold\",\n    \"size25\": \"$25,000 match threshold\",\n    \"size50\": \"$50,000 match threshold\",\n    \"size100\": \"$100,000 match threshold\",\n    \"sizeno\": \"Unstated match threshold\",\n    \"ask\": \"Suggested donation amount\",\n    \"askd1\": \"Suggested donation was highest previous contribution\",\n    \"askd2\": \"Suggested donation was 1.25 x highest previous contribution\",\n    \"askd3\": \"Suggested donation was 1.50 x highest previous contribution\",\n    \"ask1\": \"Highest previous contribution (for suggestion)\",\n    \"ask2\": \"1.25 x highest previous contribution (for suggestion)\",\n    \"ask3\": \"1.50 x highest previous contribution (for suggestion)\",\n    \"amount\": \"Dollars given\",\n    \"gave\": \"Gave anything\",\n    \"amountchange\": \"Change in amount given\",\n    \"hpa\": \"Highest previous contribution\",\n    \"ltmedmra\": \"Small prior donor: last gift was less than median $35\",\n    \"freq\": \"Number of prior donations\",\n    \"years\": \"Number of years since initial donation\",\n    \"year5\": \"At least 5 years since initial donation\",\n    \"mrm2\": \"Number of months since last donation\",\n    \"dormant\": \"Already donated in 2005\",\n    \"female\": \"Female\",\n    \"couple\": \"Couple\",\n    \"state50one\": \"State tag: 1 for one observation of each of 50 states; 0 otherwise\",\n    \"nonlit\": \"Nonlitigation\",\n    \"cases\": \"Court cases from state in 2004-5 in which organization was involved\",\n    \"statecnt\": \"Percent of sample from state\",\n    \"stateresponse\": \"Proportion of sample from the state who gave\",\n    \"stateresponset\": \"Proportion of treated sample from the state who gave\",\n    \"stateresponsec\": \"Proportion of control sample from the state who gave\",\n    \"stateresponsetminc\": \"stateresponset - stateresponsec\",\n    \"perbush\": \"State vote share for Bush\",\n    \"close25\": \"State vote share for Bush between 47.5% and 52.5%\",\n    \"red0\": \"Red state\",\n    \"blue0\": \"Blue state\",\n    \"redcty\": \"Red county\",\n    \"bluecty\": \"Blue county\",\n    \"pwhite\": \"Proportion white within zip code\",\n    \"pblack\": \"Proportion black within zip code\",\n    \"page18_39\": \"Proportion age 18-39 within zip code\",\n    \"ave_hh_sz\": \"Average household size within zip code\",\n    \"median_hhincome\": \"Median household income within zip code\",\n    \"powner\": \"Proportion house owner within zip code\",\n    \"psch_atlstba\": \"Proportion who finished college within zip code\",\n    \"pop_propurban\": \"Proportion of population urban within zip code\"\n}\n\nprint(\"\\nVariable Descriptions:\")\nfor var, desc in descriptions.items():\n    print(f\" - `{var}`: {desc}\")\n# Identify variable types\nnumerical_vars = df.select_dtypes(include=['number']).columns.tolist()\ncategorical_vars = df.select_dtypes(include=['category']).columns.tolist()\n\n# Summary statistics for numerical variables\nsummary_stats = df.describe()\n\n# Display variable types and summary\nprint(\"Numerical Variables:\")\nfor var in numerical_vars:\n    print(f\" - {var}\")\n\nprint(\"\\nCategorical Variables:\")\nfor var in categorical_vars:\n    print(f\" - {var}\")\n\nprint(\"\\nSummary Statistics for Numerical Variables:\")\nprint(summary_stats)\n\n\n\n\nVariable Descriptions:\n - `treatment`: Treatment\n - `control`: Control\n - `ratio`: Match ratio\n - `ratio2`: 2:1 match ratio\n - `ratio3`: 3:1 match ratio\n - `size`: Match threshold\n - `size25`: $25,000 match threshold\n - `size50`: $50,000 match threshold\n - `size100`: $100,000 match threshold\n - `sizeno`: Unstated match threshold\n - `ask`: Suggested donation amount\n - `askd1`: Suggested donation was highest previous contribution\n - `askd2`: Suggested donation was 1.25 x highest previous contribution\n - `askd3`: Suggested donation was 1.50 x highest previous contribution\n - `ask1`: Highest previous contribution (for suggestion)\n - `ask2`: 1.25 x highest previous contribution (for suggestion)\n - `ask3`: 1.50 x highest previous contribution (for suggestion)\n - `amount`: Dollars given\n - `gave`: Gave anything\n - `amountchange`: Change in amount given\n - `hpa`: Highest previous contribution\n - `ltmedmra`: Small prior donor: last gift was less than median $35\n - `freq`: Number of prior donations\n - `years`: Number of years since initial donation\n - `year5`: At least 5 years since initial donation\n - `mrm2`: Number of months since last donation\n - `dormant`: Already donated in 2005\n - `female`: Female\n - `couple`: Couple\n - `state50one`: State tag: 1 for one observation of each of 50 states; 0 otherwise\n - `nonlit`: Nonlitigation\n - `cases`: Court cases from state in 2004-5 in which organization was involved\n - `statecnt`: Percent of sample from state\n - `stateresponse`: Proportion of sample from the state who gave\n - `stateresponset`: Proportion of treated sample from the state who gave\n - `stateresponsec`: Proportion of control sample from the state who gave\n - `stateresponsetminc`: stateresponset - stateresponsec\n - `perbush`: State vote share for Bush\n - `close25`: State vote share for Bush between 47.5% and 52.5%\n - `red0`: Red state\n - `blue0`: Blue state\n - `redcty`: Red county\n - `bluecty`: Blue county\n - `pwhite`: Proportion white within zip code\n - `pblack`: Proportion black within zip code\n - `page18_39`: Proportion age 18-39 within zip code\n - `ave_hh_sz`: Average household size within zip code\n - `median_hhincome`: Median household income within zip code\n - `powner`: Proportion house owner within zip code\n - `psch_atlstba`: Proportion who finished college within zip code\n - `pop_propurban`: Proportion of population urban within zip code\nNumerical Variables:\n - treatment\n - control\n - ratio2\n - ratio3\n - size25\n - size50\n - size100\n - sizeno\n - askd1\n - askd2\n - askd3\n - ask1\n - ask2\n - ask3\n - amount\n - gave\n - amountchange\n - hpa\n - ltmedmra\n - freq\n - years\n - year5\n - mrm2\n - dormant\n - female\n - couple\n - state50one\n - nonlit\n - cases\n - statecnt\n - stateresponse\n - stateresponset\n - stateresponsec\n - stateresponsetminc\n - perbush\n - close25\n - red0\n - blue0\n - redcty\n - bluecty\n - pwhite\n - pblack\n - page18_39\n - ave_hh_sz\n - median_hhincome\n - powner\n - psch_atlstba\n - pop_propurban\n\nCategorical Variables:\n - ratio\n - size\n - ask\n\nSummary Statistics for Numerical Variables:\n          treatment       control        ratio2        ratio3        size25  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.666813      0.333187      0.222311      0.222211      0.166723   \nstd        0.471357      0.471357      0.415803      0.415736      0.372732   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n75%        1.000000      1.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n             size50       size100        sizeno         askd1         askd2  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.166623      0.166723      0.166743      0.222311      0.222291   \nstd        0.372643      0.372732      0.372750      0.415803      0.415790   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n       ...        redcty       bluecty        pwhite        pblack  \\\ncount  ...  49978.000000  49978.000000  48217.000000  48047.000000   \nmean   ...      0.510245      0.488715      0.819599      0.086710   \nstd    ...      0.499900      0.499878      0.168560      0.135868   \nmin    ...      0.000000      0.000000      0.009418      0.000000   \n25%    ...      0.000000      0.000000      0.755845      0.014729   \n50%    ...      1.000000      0.000000      0.872797      0.036554   \n75%    ...      1.000000      1.000000      0.938827      0.090882   \nmax    ...      1.000000      1.000000      1.000000      0.989622   \n\n          page18_39     ave_hh_sz  median_hhincome        powner  \\\ncount  48217.000000  48221.000000     48209.000000  48214.000000   \nmean       0.321694      2.429012     54815.700533      0.669418   \nstd        0.103039      0.378105     22027.316665      0.193405   \nmin        0.000000      0.000000      5000.000000      0.000000   \n25%        0.258311      2.210000     39181.000000      0.560222   \n50%        0.305534      2.440000     50673.000000      0.712296   \n75%        0.369132      2.660000     66005.000000      0.816798   \nmax        0.997544      5.270000    200001.000000      1.000000   \n\n       psch_atlstba  pop_propurban  \ncount  48215.000000   48217.000000  \nmean       0.391661       0.871968  \nstd        0.186599       0.258633  \nmin        0.000000       0.000000  \n25%        0.235647       0.884929  \n50%        0.373744       1.000000  \n75%        0.530036       1.000000  \nmax        1.000000       1.000000  \n\n[8 rows x 48 columns]\n\n\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\n# Load dataset\ndf = pd.read_stata(\"projects/HW1/karlan_list_2007.dta\")\n\n# Filter for valid mrm2 values\ndf_mrm2 = df[['mrm2', 'treatment']].dropna()\n\n# Split groups\ntreat = df_mrm2[df_mrm2['treatment'] == 1]['mrm2']\ncontrol = df_mrm2[df_mrm2['treatment'] == 0]['mrm2']\n\n# Sample statistics\nx1, x2 = treat.mean(), control.mean()\ns1, s2 = treat.std(ddof=1), control.std(ddof=1)\nn1, n2 = len(treat), len(control)\n\n# Welch's t-test manually (from slide 37)\nse_diff = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se_diff\n\n# Degrees of freedom (Welch–Satterthwaite)\ndf_num = (s1**2 / n1 + s2**2 / n2)**2\ndf_denom = ((s1**2 / n1)**2 / (n1 - 1)) + ((s2**2 / n2)**2 / (n2 - 1))\ndf_welch = df_num / df_denom\n\n# Two-sided p-value\np_val_ttest = 2 * stats.t.sf(np.abs(t_stat), df_welch)\n\n# Linear regression\nmodel = smf.ols('mrm2 ~ treatment', data=df_mrm2).fit()\n\n# Show results\nprint(f\"Welch's t-statistic: {t_stat:.3f}\")\nprint(f\"Welch's p-value: {p_val_ttest:.3f}\")\nprint(f\"Regression coefficient (treatment effect): {model.params['treatment']:.3f}\")\nprint(f\"Regression t-statistic: {model.tvalues['treatment']:.3f}\")\nprint(f\"Regression p-value: {model.pvalues['treatment']:.3f}\")\n\nWelch's t-statistic: 0.120\nWelch's p-value: 0.905\nRegression coefficient (treatment effect): 0.014\nRegression t-statistic: 0.119\nRegression p-value: 0.905"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#randomization-check-testing-baseline-balance",
    "href": "projects/HW1/hw1_questions.html#randomization-check-testing-baseline-balance",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Randomization Check: Testing Baseline Balance",
    "text": "Randomization Check: Testing Baseline Balance\nIn this section, we check if the variable mrm2 (months since last donation) is balanced across treatment and control groups. We do this using:\n\nA Welch’s t-test using the formula from class\nA linear regression of mrm2 on treatment\n\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\n# Load dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Filter for valid mrm2 values\ndf_mrm2 = df[['mrm2', 'treatment']].dropna()\n\n# Split groups\ntreat = df_mrm2[df_mrm2['treatment'] == 1]['mrm2']\ncontrol = df_mrm2[df_mrm2['treatment'] == 0]['mrm2']\n\n# Sample statistics\nx1, x2 = treat.mean(), control.mean()\ns1, s2 = treat.std(ddof=1), control.std(ddof=1)\nn1, n2 = len(treat), len(control)\n\n# Welch's t-test manually (from slide 37)\nse_diff = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se_diff\n\n# Degrees of freedom (Welch–Satterthwaite)\ndf_num = (s1**2 / n1 + s2**2 / n2)**2\ndf_denom = ((s1**2 / n1)**2 / (n1 - 1)) + ((s2**2 / n2)**2 / (n2 - 1))\ndf_welch = df_num / df_denom\n\n# Two-sided p-value\np_val_ttest = 2 * stats.t.sf(np.abs(t_stat), df_welch)\n\n# Linear regression\nmodel = smf.ols('mrm2 ~ treatment', data=df_mrm2).fit()\n\n# Show results\nprint(f\"Welch's t-statistic: {t_stat:.3f}\")\nprint(f\"Welch's p-value: {p_val_ttest:.3f}\")\nprint(f\"Regression coefficient (treatment effect): {model.params['treatment']:.3f}\")\nprint(f\"Regression t-statistic: {model.tvalues['treatment']:.3f}\")\nprint(f\"Regression p-value: {model.pvalues['treatment']:.3f}\")\n\nWelch's t-statistic: 0.120\nWelch's p-value: 0.905\nRegression coefficient (treatment effect): 0.014\nRegression t-statistic: 0.119\nRegression p-value: 0.905"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#treatment-effects-on-donation-behavior",
    "href": "projects/HW1/hw1_questions.html#treatment-effects-on-donation-behavior",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Treatment Effects on Donation Behavior",
    "text": "Treatment Effects on Donation Behavior\nWe investigate whether being offered a matching grant (treatment) increased the likelihood of making a donation.\nWe’ll: - Visualize donation rates by group - Perform a Welch’s t-test and a linear regression - Run a probit regression to match results in Table 3, Column 1\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.stats import t\n\n# Load the data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# --- Barplot: proportion who donated by treatment group ---\ndonation_rates = df.groupby('treatment')['gave'].mean()\n\nplt.figure(figsize=(10, 6))\nplt.bar(['Control', 'Treatment'], donation_rates.values)\nplt.title('Proportion of People Who Donated by Group')\nplt.ylabel('Proportion Donated')\nplt.ylim(0, 0.03)\nplt.grid(axis='y')\nplt.show()\n\n# --- Welch's t-test manually ---\ntreat = df[df['treatment'] == 1]['gave']\ncontrol = df[df['treatment'] == 0]['gave']\n\nx1, x2 = treat.mean(), control.mean()\ns1, s2 = treat.std(ddof=1), control.std(ddof=1)\nn1, n2 = len(treat), len(control)\n\nse = np.sqrt((s1**2 / n1) + (s2**2 / n2))\nt_stat = (x1 - x2) / se\ndf_num = (s1**2 / n1 + s2**2 / n2)**2\ndf_denom = ((s1**2 / n1)**2 / (n1 - 1)) + ((s2**2 / n2)**2 / (n2 - 1))\ndf_welch = df_num / df_denom\np_val_t = 2 * t.sf(np.abs(t_stat), df_welch)\n\n# --- Linear regression ---\nlm = smf.ols('gave ~ treatment', data=df).fit()\n\n# --- Probit regression ---\nprobit = smf.probit('gave ~ treatment', data=df).fit(disp=0)\n\n# --- Output summary ---\nprint(\"=== Barplot: Proportion Donated ===\")\nprint(donation_rates)\n\nprint(\"\\n=== Welch’s t-test ===\")\nprint(f\"t-statistic = {t_stat:.3f}, p-value = {p_val_t:.4f}\")\n\nprint(\"\\n=== Linear Regression ===\")\nprint(lm.summary())\n\nprint(\"\\n=== Probit Regression ===\")\nprint(probit.summary())\n\n\n\n\n\n\n\n\n=== Barplot: Proportion Donated ===\ntreatment\n0    0.017858\n1    0.022039\nName: gave, dtype: float64\n\n=== Welch’s t-test ===\nt-statistic = 3.209, p-value = 0.0013\n\n=== Linear Regression ===\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        15:00:38   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n=== Probit Regression ===\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        15:00:38   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom scipy.stats import ttest_ind\n\n# Load the dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Keep only treated individuals for ratio comparisons\ndf_treat = df[df['treatment'] == 1].copy()\n\n# Create ratio1 dummy (1 if 1:1 match ratio)\ndf_treat['ratio1'] = (df_treat['ratio'] == \"1\").astype(int)\n\n# --- T-tests: comparing response rates between ratio levels ---\ndef ttest_response(var1, var2, label1, label2):\n    g1 = df_treat[df_treat[var1] == 1]['gave']\n    g2 = df_treat[df_treat[var2] == 1]['gave']\n    t_stat, p_val = ttest_ind(g1, g2, equal_var=False)\n    print(f\"T-test: {label1} vs {label2} | t = {t_stat:.3f}, p = {p_val:.4f}\")\n\n# Run t-tests between match ratios\nttest_response('ratio1', 'ratio2', '1:1', '2:1')\nttest_response('ratio2', 'ratio3', '2:1', '3:1')\nttest_response('ratio1', 'ratio3', '1:1', '3:1')\n\n# --- Regression: gave ~ ratio1 + ratio2 + ratio3 (1:1 is omitted baseline) ---\nreg1 = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_treat).fit()\n\n# --- Alternatively: use categorical variable for ratio ---\nreg2 = smf.ols(\"gave ~ C(ratio)\", data=df_treat).fit()\n\n# --- Print regression summaries ---\nprint(\"\\nRegression with dummy variables (1:1 omitted):\")\nprint(reg1.summary())\n\nprint(\"\\nRegression with categorical ratio variable:\")\nprint(reg2.summary())\n\n# --- Response rate differences from raw data ---\nrate_1_1 = df_treat[df_treat['ratio'] == \"1\"]['gave'].mean()\nrate_2_1 = df_treat[df_treat['ratio'] == \"2\"]['gave'].mean()\nrate_3_1 = df_treat[df_treat['ratio'] == \"3\"]['gave'].mean()\n\ndiff_2_1_vs_1_1 = rate_2_1 - rate_1_1\ndiff_3_1_vs_2_1 = rate_3_1 - rate_2_1\n\nprint(f\"\\nResponse Rate Differences from Data:\")\nprint(f\"2:1 - 1:1 = {diff_2_1_vs_1_1:.4f}\")\nprint(f\"3:1 - 2:1 = {diff_3_1_vs_2_1:.4f}\")\n\n# --- Compare to regression coefficients ---\ncoef_2_1 = reg1.params['ratio2']\ncoef_3_1 = reg1.params['ratio3']\ndiff_coef_3_1_vs_2_1 = coef_3_1 - coef_2_1\n\nprint(f\"\\nResponse Rate Differences from Regression Coefficients:\")\nprint(f\"2:1 - 1:1 = {coef_2_1:.4f}\")\nprint(f\"3:1 - 2:1 = {diff_coef_3_1_vs_2_1:.4f}\")\n\nT-test: 1:1 vs 2:1 | t = nan, p = nan\nT-test: 2:1 vs 3:1 | t = -0.050, p = 0.9600\nT-test: 1:1 vs 3:1 | t = nan, p = nan\n\nRegression with dummy variables (1:1 omitted):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.524\nTime:                        15:00:38   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nRegression with categorical ratio variable:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.4263\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.734\nTime:                        15:00:38   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33392   BIC:                        -3.333e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept       1.23e+09   1.12e+10      0.110      0.912   -2.07e+10    2.32e+10\nC(ratio)[T.1]  -1.23e+09   1.12e+10     -0.110      0.912   -2.32e+10    2.07e+10\nC(ratio)[T.2]  -1.23e+09   1.12e+10     -0.110      0.912   -2.32e+10    2.07e+10\nC(ratio)[T.3]  -1.23e+09   1.12e+10     -0.110      0.912   -2.32e+10    2.07e+10\n==============================================================================\nOmnibus:                    38963.855   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506451.717\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                     3.22e+13\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 4.31e-23. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\nResponse Rate Differences from Data:\n2:1 - 1:1 = nan\n3:1 - 2:1 = nan\n\nResponse Rate Differences from Regression Coefficients:\n2:1 - 1:1 = 0.0019\n3:1 - 2:1 = 0.0001\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#effect-of-treatment-on-donation-amount",
    "href": "projects/HW1/hw1_questions.html#effect-of-treatment-on-donation-amount",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Effect of Treatment on Donation Amount",
    "text": "Effect of Treatment on Donation Amount\nWe explore whether being offered a matching grant affects: 1. How much people donate on average (unconditionally) 2. How much people donate among those who do give (conditionally) 3. The distribution of donations with annotated averages\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\n\n# Load dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# --- Unconditional regression (all people) ---\nmodel_uncond = smf.ols(\"amount ~ treatment\", data=df).fit()\nprint(\"Unconditional OLS regression (donation amount on treatment):\")\nprint(model_uncond.summary())\n\n# --- Conditional regression (only among donors) ---\ndf_donors = df[df['gave'] == 1]\nmodel_cond = smf.ols(\"amount ~ treatment\", data=df_donors).fit()\nprint(\"\\nConditional OLS regression (amount | gave == 1):\")\nprint(model_cond.summary())\n\n# --- Interpretation prompt ---\nprint(\"\\nInterpretation:\")\nprint(\"- The unconditional regression includes everyone and reflects both intensive (amount) and extensive (whether they donated) margins.\")\nprint(\"- The conditional regression isolates only the intensive margin — how much donors gave once they decided to give.\")\nprint(\"- The treatment coefficient in the conditional regression does NOT have a direct causal interpretation; it's conditional on post-treatment behavior.\")\n\n# --- Histograms of donation amounts among donors, by treatment ---\ntreat_donors = df_donors[df_donors['treatment'] == 1]['amount']\ncontrol_donors = df_donors[df_donors['treatment'] == 0]['amount']\n\nplt.figure(figsize=(14, 6))\n\n# Control group\nplt.subplot(1, 2, 1)\nplt.hist(control_donors, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\nplt.axvline(control_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group: Donation Amounts (Among Donors)')\nplt.xlabel('Amount Donated')\nplt.ylabel('Frequency')\nplt.text(control_donors.mean(), plt.ylim()[1]*0.9, f\"Mean: {control_donors.mean():.2f}\", color='red')\n\n# Treatment group\nplt.subplot(1, 2, 2)\nplt.hist(treat_donors, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.axvline(treat_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group: Donation Amounts (Among Donors)')\nplt.xlabel('Amount Donated')\nplt.ylabel('Frequency')\nplt.text(treat_donors.mean(), plt.ylim()[1]*0.9, f\"Mean: {treat_donors.mean():.2f}\", color='red')\n\nplt.tight_layout()\nplt.show()\n\nUnconditional OLS regression (donation amount on treatment):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        15:00:38   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nConditional OLS regression (amount | gave == 1):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        15:00:38   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nInterpretation:\n- The unconditional regression includes everyone and reflects both intensive (amount) and extensive (whether they donated) margins.\n- The conditional regression isolates only the intensive margin — how much donors gave once they decided to give.\n- The treatment coefficient in the conditional regression does NOT have a direct causal interpretation; it's conditional on post-treatment behavior."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#simulated-cumulative-differences",
    "href": "projects/HW1/hw1_questions.html#simulated-cumulative-differences",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulated Cumulative Differences",
    "text": "Simulated Cumulative Differences\nTo simulate the intuition behind comparing group means, we draw: - 100,000 samples from the control group donation distribution - 10,000 samples from the treatment group We compute the difference between paired samples and plot the cumulative average of the differences.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Use unconditional donation amount distributions\ncontrol_dist = df[df['treatment'] == 0]['amount']\ntreatment_dist = df[df['treatment'] == 1]['amount']\n\n# Simulate draws\nnp.random.seed(42)\nsim_control = np.random.choice(control_dist, size=100000, replace=True)\nsim_treat = np.random.choice(treatment_dist, size=10000, replace=True)\n\n# Match lengths for subtraction (repeat treatment sample)\nsim_treat_matched = np.tile(sim_treat, 10)  # Now length = 100000\n\n# Compute vector of differences\ndiffs = sim_treat_matched - sim_control\n\n# Compute cumulative average\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# True difference in means\ntrue_diff = treatment_dist.mean() - control_dist.mean()\n\n# Plot\nplt.figure(figsize=(12, 6))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences')\nplt.axhline(true_diff, color='red', linestyle='--', linewidth=2, label='True Mean Difference')\nplt.xlabel('Number of Samples')\nplt.ylabel('Cumulative Average (Treatment - Control)')\nplt.title('Simulated Cumulative Average of Donation Differences')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Display true difference for interpretation\nprint(f\"\\nTrue difference in average donation amount (treatment - control): {true_diff:.4f}\")\n\n\n\n\n\n\n\n\n\nTrue difference in average donation amount (treatment - control): 0.1536\n\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#simulated-distribution-of-average-differences-at-varying-sample-sizes",
    "href": "projects/HW1/hw1_questions.html#simulated-distribution-of-average-differences-at-varying-sample-sizes",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulated Distribution of Average Differences at Varying Sample Sizes",
    "text": "Simulated Distribution of Average Differences at Varying Sample Sizes\nWe simulate 1000 experiments at each sample size (50, 200, 500, 1000). Each experiment: - Takes independent samples from control and treatment donation distributions - Computes the mean difference in donations We then plot histograms of these mean differences and observe whether zero falls near the center or in the tails.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Extract full distributions\ncontrol = df[df['treatment'] == 0]['amount'].values\ntreatment = df[df['treatment'] == 1]['amount'].values\n\n# Sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# Prepare for plots\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\naxs = axs.flatten()\n\n# Run simulation and plotting loop\nnp.random.seed(123)\nfor i, n in enumerate(sample_sizes):\n    diff_means = []\n    for _ in range(n_simulations):\n        sample_control = np.random.choice(control, n, replace=True)\n        sample_treatment = np.random.choice(treatment, n, replace=True)\n        diff_means.append(sample_treatment.mean() - sample_control.mean())\n    \n    axs[i].hist(diff_means, bins=30, color='skyblue', edgecolor='black')\n    axs[i].axvline(0, color='red', linestyle='--', linewidth=2, label=\"Zero\")\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Average Difference (Treatment - Control)\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.suptitle(\"Distributions of Average Differences from 1000 Simulated Experiments\")\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()"
  },
  {
    "objectID": "projects/HW2/Interactive-1.html",
    "href": "projects/HW2/Interactive-1.html",
    "title": "Nadifa's Awesome Work",
    "section": "",
    "text": "import pandas as pd\n\n# Read the blueprinty data\nblueprinty = pd.read_csv(\"blueprinty.csv\")\nblueprinty.head()\n\n\n_todo: Compare histograms and means of number of patents by customer status. What do you observe?_\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n_todo: Compare regions and ages by customer status. What do you observe?_\n\n\n### Estimation of Simple Poisson Model\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n_todo: Write down mathematically the likelihood for_ $Y \\sim \\text{Poisson}(\\lambda)$. Note that $f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!$.\n\n_todo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:_\n\n\nRunning cells with 'Python 3.12.3' requires the ipykernel package.\n\n&lt;a href='command:jupyter.createPythonEnvAndSelectController'&gt;Create a Python Environment&lt;/a&gt; with the required packages.\n\nOr install 'ipykernel' using the command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'\n\n\n\n\nimport pandas as pd\n\n# Read the blueprinty data\nblueprinty = pd.read_csv(\"blueprinty.csv\")\nblueprinty.head()\n\n\n_todo: Compare histograms and means of number of patents by customer status. What do you observe?_\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n_todo: Compare regions and ages by customer status. What do you observe?_\n\n\n### Estimation of Simple Poisson Model\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n_todo: Write down mathematically the likelihood for_ $Y \\sim \\text{Poisson}(\\lambda)$. Note that $f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!$.\n\n_todo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:_\n\n\nRunning cells with 'Python 3.12.3' requires the ipykernel package.\n\n&lt;a href='command:jupyter.createPythonEnvAndSelectController'&gt;Create a Python Environment&lt;/a&gt; with the required packages.\n\n\n\nConnected to base (Python 3.12.7)\n\nimport pandas as pd\n\n# Read the blueprinty data\nblueprinty = pd.read_csv(\"blueprinty.csv\")\nblueprinty.head()\n\n\n_todo: Compare histograms and means of number of patents by customer status. What do you observe?_\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n_todo: Compare regions and ages by customer status. What do you observe?_\n\n\n### Estimation of Simple Poisson Model\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n_todo: Write down mathematically the likelihood for_ $Y \\sim \\text{Poisson}(\\lambda)$. Note that $f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!$.\n\n_todo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:_\n\n\n  Cell In[1], line 8\n    _todo: Compare histograms and means of number of patents by customer status. What do you observe?_\n                   ^\nSyntaxError: invalid syntax\n\n\n\n\n\nimport pandas as pd\n\n# Read the blueprinty data\nblueprinty = pd.read_csv(\"blueprinty.csv\")\nblueprinty.head()\n\n\n_todo: Compare histograms and means of number of patents by customer status. What do you observe?_\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n_todo: Compare regions and ages by customer status. What do you observe?_\n\n\n### Estimation of Simple Poisson Model\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n_todo: Write down mathematically the likelihood for_ $Y \\sim \\text{Poisson}(\\lambda)$. Note that $f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!$.\n\n_todo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:_\n\n\n  Cell In[2], line 8\n    _todo: Compare histograms and means of number of patents by customer status. What do you observe?_\n                   ^\nSyntaxError: invalid syntax\n\n\n\n\n\nimport pandas as pd\n\n# Read the blueprinty data\nblueprinty = pd.read_csv(\"blueprinty.csv\")\nblueprinty.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Check unique values for customer_status\nprint(\"Customer status values:\", blueprinty['customer_status'].unique())\n\n# Set up the figure\nplt.figure(figsize=(10, 8))\nsns.histplot(data=blueprinty, x=\"number_of_patents\", hue=\"customer_status\", kde=True, multiple=\"stack\")\nplt.title(\"Distribution of Number of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Compare means\nmeans = blueprinty.groupby(\"customer_status\")[\"number_of_patents\"].mean()\nprint(\"Mean number of patents by customer status:\")\nprint(means)\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nFile /opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805, in Index.get_loc(self, key)\n   3804 try:\n-&gt; 3805     return self._engine.get_loc(casted_key)\n   3806 except KeyError as err:\n\nFile index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()\n\nFile index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()\n\nFile pandas/_libs/hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nFile pandas/_libs/hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nKeyError: 'customer_status'\n\nThe above exception was the direct cause of the following exception:\n\nKeyError                                  Traceback (most recent call last)\nFile /home/jovyan/Desktop/mysite/projects/HW2/hw2_questions.qmd:5\n      2 import seaborn as sns\n      4 # Check unique values for customer_status\n----&gt; 5 print(\"Customer status values:\", blueprinty['customer_status'].unique())\n      7 # Set up the figure\n      8 plt.figure(figsize=(10, 8))\n\nFile /opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:4102, in DataFrame.__getitem__(self, key)\n   4100 if self.columns.nlevels &gt; 1:\n   4101     return self._getitem_multilevel(key)\n-&gt; 4102 indexer = self.columns.get_loc(key)\n   4103 if is_integer(indexer):\n   4104     indexer = [indexer]\n\nFile /opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812, in Index.get_loc(self, key)\n   3807     if isinstance(casted_key, slice) or (\n   3808         isinstance(casted_key, abc.Iterable)\n   3809         and any(isinstance(x, slice) for x in casted_key)\n   3810     ):\n   3811         raise InvalidIndexError(key)\n-&gt; 3812     raise KeyError(key) from err\n   3813 except TypeError:\n   3814     # If we have a listlike key, _check_indexing_error will raise\n   3815     #  InvalidIndexError. Otherwise we fall through and re-raise\n   3816     #  the TypeError.\n   3817     self._check_indexing_error(key)\n\nKeyError: 'customer_status'\n\n\n\n\nprint(blueprinty.columns.tolist())\n\n['patents', 'region', 'age', 'iscustomer']\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Check unique values for iscustomer\nprint(\"Customer status values:\", blueprinty['iscustomer'].unique())\n\n# Plot histogram\nplt.figure(figsize=(10, 8))\nsns.histplot(data=blueprinty, x=\"patents\", hue=\"iscustomer\", kde=True, multiple=\"stack\")\nplt.title(\"Distribution of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Compare means\nmeans = blueprinty.groupby(\"iscustomer\")[\"patents\"].mean()\nprint(\"Mean number of patents by customer status:\")\nprint(means)\n\nCustomer status values: [0 1]\n\n\n\n\n\n\n\n\n\nMean number of patents by customer status:\niscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\n\n# Plot region counts by customer status\nplt.figure(figsize=(10, 8))\nsns.countplot(data=blueprinty, x=\"region\", hue=\"iscustomer\")\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\nplt.show()\n\n# Plot age distribution by customer status\nplt.figure(figsize=(10, 8))\nsns.boxplot(data=blueprinty, x=\"iscustomer\", y=\"age\")\nplt.title(\"Age Distribution by Customer Status\")\nplt.xlabel(\"Customer Status\")\nplt.ylabel(\"Age\")\nplt.show()\n\n# Compute mean ages by status\nmean_ages = blueprinty.groupby(\"iscustomer\")[\"age\"].mean()\nprint(\"Mean age by customer status:\")\nprint(mean_ages)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean age by customer status:\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\n\nimport numpy as np\n\ndef poisson_loglikelihood(lmbda, Y):\n    \"\"\"\n    Compute the log-likelihood for Poisson-distributed data.\n\n    Parameters:\n    - lmbda: float, Poisson rate parameter λ\n    - Y: array-like, observed count data\n\n    Returns:\n    - float, log-likelihood value\n    \"\"\"\n    Y = np.array(Y)\n    if lmbda &lt;= 0:\n        return -np.inf  # log-likelihood undefined for non-positive lambda\n    log_lik = np.sum(-lmbda + Y * np.log(lmbda) - np.log(np.factorial(Y)))\n    return log_lik\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Use observed patents as Y\nY = blueprinty[\"patents\"].values\n\n# Define lambda values\nlambda_vals = np.linspace(0.1, 20, 200)\nloglik_vals = [poisson_loglikelihood(lmbda, Y) for lmbda in lambda_vals]\n\n# Plot log-likelihood\nplt.figure(figsize=(10, 8))\nplt.plot(lambda_vals, loglik_vals)\nplt.title(\"Poisson Log-Likelihood vs Lambda\")\nplt.xlabel(\"Lambda\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True)\nplt.show()\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nFile /home/jovyan/Desktop/mysite/projects/HW2/hw2_questions.qmd:9\n      7 # Define lambda values\n      8 lambda_vals = np.linspace(0.1, 20, 200)\n----&gt; 9 loglik_vals = [poisson_loglikelihood(lmbda, Y) for lmbda in lambda_vals]\n     11 # Plot log-likelihood\n     12 plt.figure(figsize=(10, 8))\n\nCell In[8], line 17, in poisson_loglikelihood(lmbda, Y)\n     15 if lmbda &lt;= 0:\n     16     return -np.inf  # log-likelihood undefined for non-positive lambda\n---&gt; 17 log_lik = np.sum(-lmbda + Y * np.log(lmbda) - np.log(np.factorial(Y)))\n     18 return log_lik\n\nFile ~/.rsm-msba/lib/python3.12/site-packages/numpy/__init__.py:333, in __getattr__(attr)\n    330     \"Removed in NumPy 1.25.0\"\n    331     raise RuntimeError(\"Tester was removed in NumPy 1.25.\")\n--&gt; 333 raise AttributeError(\"module {!r} has no attribute \"\n    334                      \"{!r}\".format(__name__, attr))\n\nAttributeError: module 'numpy' has no attribute 'factorial'\n\n\n\n\nimport numpy as np\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lmbda, Y):\n    \"\"\"\n    Compute the log-likelihood for Poisson-distributed data.\n\n    Parameters:\n    - lmbda: float, Poisson rate parameter λ\n    - Y: array-like, observed count data\n\n    Returns:\n    - float, log-likelihood value\n    \"\"\"\n    Y = np.array(Y)\n    if lmbda &lt;= 0:\n        return -np.inf  # log-likelihood undefined for non-positive lambda\n    log_lik = np.sum(-lmbda + Y * np.log(lmbda) - np.log(factorial(Y)))\n    return log_lik\n\n\nimport numpy as np\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lmbda, Y):\n    \"\"\"\n    Compute the log-likelihood for Poisson-distributed data.\n\n    Parameters:\n    - lmbda: float, Poisson rate parameter λ\n    - Y: array-like, observed count data\n\n    Returns:\n    - float, log-likelihood value\n    \"\"\"\n    Y = np.array(Y)\n    if lmbda &lt;= 0:\n        return -np.inf  # log-likelihood undefined for non-positive lambda\n    log_lik = np.sum(-lmbda + Y * np.log(lmbda) - np.log(factorial(Y)))\n    return log_lik\n\n\n# Use the patent data\nY = blueprinty[\"patents\"].values\n\n# Range of lambda values\nlambda_vals = np.linspace(0.1, 20, 200)\nloglik_vals = [poisson_loglikelihood(lmbda, Y) for lmbda in lambda_vals]\n\n# Plot\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 8))\nplt.plot(lambda_vals, loglik_vals)\nplt.title(\"Poisson Log-Likelihood vs Lambda\")\nplt.xlabel(\"Lambda\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport sympy as sp\n\n# Define symbols\nlmbda, Y1, Y2, Y3 = sp.symbols(\"lambda Y1 Y2 Y3\", positive=True)\n\n# Example: 3 observations (you can generalize this)\nloglik = (-lmbda + Y1 * sp.log(lmbda)) + \\\n         (-lmbda + Y2 * sp.log(lmbda)) + \\\n         (-lmbda + Y3 * sp.log(lmbda))\n\n# Simplify\nloglik = sp.simplify(loglik)\n\n# Take derivative with respect to lambda\ndloglik = sp.diff(loglik, lmbda)\n\n# Solve derivative = 0\nlambda_mle = sp.solve(dloglik, lmbda)\nlambda_mle\n\n[Y1/3 + Y2/3 + Y3/3]\n\n\n\nfrom scipy.optimize import minimize_scalar\n\n# Negative log-likelihood\ndef neg_loglikelihood(lmbda):\n    return -poisson_loglikelihood(lmbda, Y)\n\n# Optimize (bounded to avoid λ ≤ 0)\nresult = minimize_scalar(neg_loglikelihood, bounds=(0.1, 20), method='bounded')\n\n# Output the estimated lambda\nlambda_mle = result.x\nlambda_mle\n\n3.6846666212929713\n\n\n\nimport numpy as np\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    \"\"\"\n    Log-likelihood for Poisson regression.\n\n    Parameters:\n    - beta: array-like, coefficients (shape: p,)\n    - Y: array-like, response variable (counts)\n    - X: array-like, design matrix (shape: n x p)\n\n    Returns:\n    - float, total log-likelihood\n    \"\"\"\n    beta = np.array(beta)\n    X = np.array(X)\n    Y = np.array(Y)\n\n    # Compute lambda_i = exp(X_i' * beta)\n    lambda_vals = np.exp(X @ beta)\n\n    # Log-likelihood\n    log_lik = np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n    return log_lik\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom scipy.special import factorial\nfrom numpy.linalg import inv\n\n# 1. Build design matrix X\nblueprinty = blueprinty.copy()\nblueprinty[\"age_squared\"] = blueprinty[\"age\"] ** 2\n\n# Get dummies for region (drop one for reference)\nregion_dummies = pd.get_dummies(blueprinty[\"region\"], drop_first=True)\n\n# Combine features\nX = pd.concat([\n    pd.Series(1, index=blueprinty.index, name=\"intercept\"),\n    blueprinty[[\"age\", \"age_squared\", \"iscustomer\"]],\n    region_dummies\n], axis=1).astype(float)\n\nY = blueprinty[\"patents\"].values\nX_mat = X.values\n\n# 2. Define the negative log-likelihood\ndef neg_poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    lambda_vals = np.exp(X @ beta)\n    return -np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n\n# 3. Optimize\ninit_beta = np.zeros(X.shape[1])\nresult = minimize(neg_poisson_regression_loglikelihood, init_beta, args=(Y, X_mat), method=\"BFGS\")\n\n# Estimated coefficients\nbeta_hat = result.x\n\n# 4. Get standard errors from Hessian\nhessian_inv = result.hess_inv\nse = np.sqrt(np.diag(hessian_inv))\n\n# 5. Create summary table\nsummary_table = pd.DataFrame({\n    \"Coefficient\": beta_hat,\n    \"Std. Error\": se\n}, index=X.columns)\n\nsummary_table\n\nRuntimeWarning: overflow encountered in exp\n  lambda_vals = np.exp(X @ beta)\n&lt;ipython-input-16-8f3525de8a6e&gt;:28: RuntimeWarning: invalid value encountered in multiply\n  return -np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n&lt;ipython-input-16-8f3525de8a6e&gt;:28: RuntimeWarning: invalid value encountered in add\n  return -np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n/home/jovyan/.rsm-msba/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n&lt;ipython-input-16-8f3525de8a6e&gt;:27: RuntimeWarning: overflow encountered in exp\n  lambda_vals = np.exp(X @ beta)\n&lt;ipython-input-16-8f3525de8a6e&gt;:28: RuntimeWarning: invalid value encountered in multiply\n  return -np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n&lt;ipython-input-16-8f3525de8a6e&gt;:28: RuntimeWarning: invalid value encountered in add\n  return -np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n/home/jovyan/.rsm-msba/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n&lt;ipython-input-16-8f3525de8a6e&gt;:27: RuntimeWarning: overflow encountered in exp\n  lambda_vals = np.exp(X @ beta)\n&lt;ipython-input-16-8f3525de8a6e&gt;:28: RuntimeWarning: invalid value encountered in multiply\n  return -np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n&lt;ipython-input-16-8f3525de8a6e&gt;:28: RuntimeWarning: invalid value encountered in add\n  return -np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n1.480059\n1.0\n\n\nage\n38.016417\n1.0\n\n\nage_squared\n1033.539585\n1.0\n\n\niscustomer\n0.553874\n1.0\n\n\nNortheast\n0.640979\n1.0\n\n\nNorthwest\n0.164288\n1.0\n\n\nSouth\n0.181562\n1.0\n\n\nSouthwest\n0.295497\n1.0\n\n\n\n\n\n\n\n\nimport statsmodels.api as sm\n\n# Fit Poisson regression using statsmodels\nglm_model = sm.GLM(Y, X_mat, family=sm.families.Poisson())\nglm_results = glm_model.fit()\n\n# Print summary\nglm_results.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ny\nNo. Observations:\n1500\n\n\nModel:\nGLM\nDf Residuals:\n1492\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3258.1\n\n\nDate:\nTue, 06 May 2025\nDeviance:\n2143.3\n\n\nTime:\n13:35:11\nPearson chi2:\n2.07e+03\n\n\nNo. Iterations:\n5\nPseudo R-squ. (CS):\n0.1360\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-0.5089\n0.183\n-2.778\n0.005\n-0.868\n-0.150\n\n\nx1\n0.1486\n0.014\n10.716\n0.000\n0.121\n0.176\n\n\nx2\n-0.0030\n0.000\n-11.513\n0.000\n-0.003\n-0.002\n\n\nx3\n0.2076\n0.031\n6.719\n0.000\n0.147\n0.268\n\n\nx4\n0.0292\n0.044\n0.669\n0.504\n-0.056\n0.115\n\n\nx5\n-0.0176\n0.054\n-0.327\n0.744\n-0.123\n0.088\n\n\nx6\n0.0566\n0.053\n1.074\n0.283\n-0.047\n0.160\n\n\nx7\n0.0506\n0.047\n1.072\n0.284\n-0.042\n0.143\n\n\n\n\n\n\n# Step 1: Create X_0 (iscustomer = 0) and X_1 (iscustomer = 1)\nX_0 = X.copy()\nX_1 = X.copy()\nX_0[\"iscustomer\"] = 0\nX_1[\"iscustomer\"] = 1\n\n# Step 2: Predict expected patent counts under each scenario\n# Get design matrices\nX_0_mat = X_0.values\nX_1_mat = X_1.values\n\n# Use fitted beta_hat from previous optimization or glm\nlambda_0 = np.exp(X_0_mat @ beta_hat)\nlambda_1 = np.exp(X_1_mat @ beta_hat)\n\n# Step 3: Compute average treatment effect (ATE)\ndiffs = lambda_1 - lambda_0\nate = np.mean(diffs)\nate\n\nRuntimeWarning: overflow encountered in exp\n  lambda_0 = np.exp(X_0_mat @ beta_hat)\n&lt;ipython-input-18-1a85489e9279&gt;:14: RuntimeWarning: overflow encountered in exp\n  lambda_1 = np.exp(X_1_mat @ beta_hat)\n&lt;ipython-input-18-1a85489e9279&gt;:17: RuntimeWarning: invalid value encountered in subtract\n  diffs = lambda_1 - lambda_0\n\n\nnan\n\n\n\n# Create counterfactual datasets\nX_0 = X.copy()\nX_1 = X.copy()\nX_0[\"iscustomer\"] = 0\nX_1[\"iscustomer\"] = 1\nX_0_mat = X_0.values\nX_1_mat = X_1.values\n\n# Predict expected patent counts\nlambda_0 = np.exp(X_0_mat @ beta_hat)\nlambda_1 = np.exp(X_1_mat @ beta_hat)\n\n# Compute average treatment effect\ndiffs = lambda_1 - lambda_0\nate = np.mean(diffs)\nate\n\nRuntimeWarning: overflow encountered in exp\n  lambda_0 = np.exp(X_0_mat @ beta_hat)\n&lt;ipython-input-19-93ab39b1dafe&gt;:11: RuntimeWarning: overflow encountered in exp\n  lambda_1 = np.exp(X_1_mat @ beta_hat)\n&lt;ipython-input-19-93ab39b1dafe&gt;:14: RuntimeWarning: invalid value encountered in subtract\n  diffs = lambda_1 - lambda_0\n\n\nnan\n\n\n\nimport pandas as pd\n\n# Load Airbnb data\nairbnb = pd.read_csv(\"airbnb.csv\")\n\n# Keep relevant columns\ncolumns_to_keep = [\n    \"room_type\", \"bathrooms\", \"bedrooms\", \"price\", \"number_of_reviews\",\n    \"review_scores_cleanliness\", \"review_scores_location\",\n    \"review_scores_value\", \"instant_bookable\"\n]\n\nairbnb = airbnb[columns_to_keep]\n\n# Drop rows with missing values in these columns\nairbnb_clean = airbnb.dropna()\n\n# Convert instant_bookable to binary\nairbnb_clean[\"instant_bookable\"] = airbnb_clean[\"instant_bookable\"].map({\"t\": 1, \"f\": 0})\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  airbnb_clean[\"instant_bookable\"] = airbnb_clean[\"instant_bookable\"].map({\"t\": 1, \"f\": 0})\n\n\n\nimport pandas as pd\n\n# Load Airbnb data\nairbnb = pd.read_csv(\"airbnb.csv\")\n\n# Keep relevant columns\ncolumns_to_keep = [\n    \"room_type\", \"bathrooms\", \"bedrooms\", \"price\", \"number_of_reviews\",\n    \"review_scores_cleanliness\", \"review_scores_location\",\n    \"review_scores_value\", \"instant_bookable\"\n]\n\nairbnb = airbnb[columns_to_keep]\n\n# Drop rows with missing values in these columns\nairbnb_clean = airbnb.dropna()\n\n# Convert instant_bookable to binary\nairbnb_clean.loc[:, \"instant_bookable\"] = airbnb_clean[\"instant_bookable\"].map({\"t\": 1, \"f\": 0})\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 8))\nsns.histplot(airbnb_clean[\"number_of_reviews\"], bins=50, kde=False)\nplt.title(\"Distribution of Number of Reviews\")\nplt.xlabel(\"Number of Reviews\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\nairbnb_clean.describe()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\n\n\n\n\ncount\n30160.000000\n30160.000000\n30160.000000\n30160.000000\n30160.000000\n30160.000000\n30160.000000\n\n\nmean\n1.122132\n1.151459\n140.206863\n21.170889\n9.201724\n9.415351\n9.333952\n\n\nstd\n0.384916\n0.699010\n188.392314\n32.007541\n1.114261\n0.843185\n0.900472\n\n\nmin\n0.000000\n0.000000\n10.000000\n1.000000\n2.000000\n2.000000\n2.000000\n\n\n25%\n1.000000\n1.000000\n70.000000\n3.000000\n9.000000\n9.000000\n9.000000\n\n\n50%\n1.000000\n1.000000\n103.000000\n8.000000\n10.000000\n10.000000\n10.000000\n\n\n75%\n1.000000\n1.000000\n169.000000\n26.000000\n10.000000\n10.000000\n10.000000\n\n\nmax\n6.000000\n10.000000\n10000.000000\n421.000000\n10.000000\n10.000000\n10.000000\n\n\n\n\n\n\n\n\nimport numpy as np\nimport statsmodels.api as sm\n\n# Create dummy variables for room type (drop one)\nroom_dummies = pd.get_dummies(airbnb_clean[\"room_type\"], drop_first=True)\n\n# Build design matrix\nX = pd.concat([\n    pd.Series(1, index=airbnb_clean.index, name=\"intercept\"),\n    airbnb_clean[[\"bathrooms\", \"bedrooms\", \"price\",\n                  \"review_scores_cleanliness\", \"review_scores_location\",\n                  \"review_scores_value\", \"instant_bookable\"]],\n    room_dummies\n], axis=1)\n\nY = airbnb_clean[\"number_of_reviews\"]\n\n# Fit Poisson model\npoisson_model = sm.GLM(Y, X, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\npoisson_results.summary()\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nFile /home/jovyan/Desktop/mysite/projects/HW2/hw2_questions.qmd:19\n     16 Y = airbnb_clean[\"number_of_reviews\"]\n     18 # Fit Poisson model\n---&gt; 19 poisson_model = sm.GLM(Y, X, family=sm.families.Poisson())\n     20 poisson_results = poisson_model.fit()\n     21 poisson_results.summary()\n\nFile /opt/conda/lib/python3.12/site-packages/statsmodels/genmod/generalized_linear_model.py:326, in GLM.__init__(self, endog, exog, family, offset, exposure, freq_weights, var_weights, missing, **kwargs)\n    323 self.freq_weights = freq_weights\n    324 self.var_weights = var_weights\n--&gt; 326 super().__init__(endog, exog, missing=missing,\n    327                           offset=offset, exposure=exposure,\n    328                           freq_weights=freq_weights,\n    329                           var_weights=var_weights, **kwargs)\n    330 self._check_inputs(family, self.offset, self.exposure, self.endog,\n    331                    self.freq_weights, self.var_weights)\n    332 if offset is None:\n\nFile /opt/conda/lib/python3.12/site-packages/statsmodels/base/model.py:270, in LikelihoodModel.__init__(self, endog, exog, **kwargs)\n    269 def __init__(self, endog, exog=None, **kwargs):\n--&gt; 270     super().__init__(endog, exog, **kwargs)\n    271     self.initialize()\n\nFile /opt/conda/lib/python3.12/site-packages/statsmodels/base/model.py:95, in Model.__init__(self, endog, exog, **kwargs)\n     93 missing = kwargs.pop('missing', 'none')\n     94 hasconst = kwargs.pop('hasconst', None)\n---&gt; 95 self.data = self._handle_data(endog, exog, missing, hasconst,\n     96                               **kwargs)\n     97 self.k_constant = self.data.k_constant\n     98 self.exog = self.data.exog\n\nFile /opt/conda/lib/python3.12/site-packages/statsmodels/base/model.py:135, in Model._handle_data(self, endog, exog, missing, hasconst, **kwargs)\n    134 def _handle_data(self, endog, exog, missing, hasconst, **kwargs):\n--&gt; 135     data = handle_data(endog, exog, missing, hasconst, **kwargs)\n    136     # kwargs arrays could have changed, easier to just attach here\n    137     for key in kwargs:\n\nFile /opt/conda/lib/python3.12/site-packages/statsmodels/base/data.py:675, in handle_data(endog, exog, missing, hasconst, **kwargs)\n    672     exog = np.asarray(exog)\n    674 klass = handle_data_class_factory(endog, exog)\n--&gt; 675 return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n    676              **kwargs)\n\nFile /opt/conda/lib/python3.12/site-packages/statsmodels/base/data.py:84, in ModelData.__init__(self, endog, exog, missing, hasconst, **kwargs)\n     82     self.orig_endog = endog\n     83     self.orig_exog = exog\n---&gt; 84     self.endog, self.exog = self._convert_endog_exog(endog, exog)\n     86 self.const_idx = None\n     87 self.k_constant = 0\n\nFile /opt/conda/lib/python3.12/site-packages/statsmodels/base/data.py:509, in PandasData._convert_endog_exog(self, endog, exog)\n    507 exog = exog if exog is None else np.asarray(exog)\n    508 if endog.dtype == object or exog is not None and exog.dtype == object:\n--&gt; 509     raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n    510                      \"Check input data with np.asarray(data).\")\n    511 return super()._convert_endog_exog(endog, exog)\n\nValueError: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
  },
  {
    "objectID": "projects/HW2/hw2_questions.html",
    "href": "projects/HW2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\n\n# Read the blueprinty data\nblueprinty = pd.read_csv(\"blueprinty.csv\")\nblueprinty.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Check unique values for iscustomer\nprint(\"Customer status values:\", blueprinty['iscustomer'].unique())\n\n# Plot histogram\nplt.figure(figsize=(10, 8))\nsns.histplot(data=blueprinty, x=\"patents\", hue=\"iscustomer\", kde=True, multiple=\"stack\")\nplt.title(\"Distribution of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Compare means\nmeans = blueprinty.groupby(\"iscustomer\")[\"patents\"].mean()\nprint(\"Mean number of patents by customer status:\")\nprint(means)\n\nCustomer status values: [0 1]\n\n\n\n\n\n\n\n\n\nMean number of patents by customer status:\niscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\n\n\n\n\nPlots overlapping histograms of number_of_patents by customer_status.\nComputes and prints the mean number_of_patents for each group.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n# Plot region counts by customer status\nplt.figure(figsize=(10, 8))\nsns.countplot(data=blueprinty, x=\"region\", hue=\"iscustomer\")\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\nplt.show()\n\n# Plot age distribution by customer status\nplt.figure(figsize=(10, 8))\nsns.boxplot(data=blueprinty, x=\"iscustomer\", y=\"age\")\nplt.title(\"Age Distribution by Customer Status\")\nplt.xlabel(\"Customer Status\")\nplt.ylabel(\"Age\")\nplt.show()\n\n# Compute mean ages by status\nmean_ages = blueprinty.groupby(\"iscustomer\")[\"age\"].mean()\nprint(\"Mean age by customer status:\")\nprint(mean_ages)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean age by customer status:\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nLet ( Y_1, Y_2, , Y_n ) be independent observations, each distributed as ( Y_i () ).\nThe probability mass function of the Poisson distribution is:\n[ f(Y_i|) = ]\nThe likelihood function for ( n ) observations is:\n[ L(; Y_1, , Y_n) = _{i=1}^{n} = e^{-n} {{i=1}^{n} Y_i} {i=1}{n} ]\nThe log-likelihood is:\n[ L() = -n+ ({i=1}^{n} Y_i) - {i=1}^{n} Y_i! ]\n\n\n\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_loglikelihood(lambd, Y):\n    \"\"\"\n    Compute the log-likelihood of observing data Y under a Poisson model with rate lambda.\n\n    Parameters:\n    - lambd: float, rate parameter (λ) of the Poisson distribution\n    - Y: array-like, observed data\n\n    Returns:\n    - float, the log-likelihood value\n    \"\"\"\n    Y = np.array(Y)\n    if lambd &lt;= 0:\n        return -np.inf  # log-likelihood is undefined for λ ≤ 0\n    return np.sum(Y * np.log(lambd) - lambd - gammaln(Y + 1))\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndf = pd.read_csv(\"blueprinty.csv\")\n\n# Assume the observed count variable is named 'patents'\nY = df['patents'].dropna()\n\n# Range of lambda values to test\nlambda_vals = np.linspace(0.1, 20, 200)\nlog_likelihood_vals = [poisson_loglikelihood(lamb, Y) for lamb in lambda_vals]\n\n# Plot\nplt.figure(figsize=(10, 8))\nplt.plot(lambda_vals, log_likelihood_vals)\nplt.title(\"Log-Likelihood of Poisson Model\")\nplt.xlabel(\"Lambda (λ)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport sympy as sp\n\n# Define symbols\nlmbda, Y1, Y2, Y3 = sp.symbols(\"lambda Y1 Y2 Y3\", positive=True)\n\n# Example: 3 observations (you can generalize this)\nloglik = (-lmbda + Y1 * sp.log(lmbda)) + \\\n         (-lmbda + Y2 * sp.log(lmbda)) + \\\n         (-lmbda + Y3 * sp.log(lmbda))\n\n# Simplify\nloglik = sp.simplify(loglik)\n\n# Take derivative with respect to lambda\ndloglik = sp.diff(loglik, lmbda)\n\n# Solve derivative = 0\nlambda_mle = sp.solve(dloglik, lmbda)\nlambda_mle\n\n[Y1/3 + Y2/3 + Y3/3]\n\n\n\nfrom scipy.optimize import minimize_scalar\n\n# Negative log-likelihood\ndef neg_loglikelihood(lmbda):\n    return -poisson_loglikelihood(lmbda, Y)\n\n# Optimize (bounded to avoid λ ≤ 0)\nresult = minimize_scalar(neg_loglikelihood, bounds=(0.1, 20), method='bounded')\n\n# Output the estimated lambda\nlambda_mle = result.x\nlambda_mle\n\n3.6846666212929713\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\nimport numpy as np\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    \"\"\"\n    Log-likelihood for Poisson regression.\n\n    Parameters:\n    - beta: array-like, coefficients (shape: p,)\n    - Y: array-like, response variable (counts)\n    - X: array-like, design matrix (shape: n x p)\n\n    Returns:\n    - float, total log-likelihood\n    \"\"\"\n    beta = np.array(beta)\n    X = np.array(X)\n    Y = np.array(Y)\n\n    # Compute lambda_i = exp(X_i' * beta)\n    lambda_vals = np.exp(X @ beta)\n\n    # Log-likelihood\n    log_lik = np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n    return log_lik\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom scipy.special import factorial\nfrom numpy.linalg import inv\n\n# 1. Build design matrix X\nblueprinty = blueprinty.copy()\nblueprinty[\"age_squared\"] = blueprinty[\"age\"] ** 2\n\n# Get dummies for region (drop one for reference)\nregion_dummies = pd.get_dummies(blueprinty[\"region\"], drop_first=True)\n\n# Combine features\nX = pd.concat([\n    pd.Series(1, index=blueprinty.index, name=\"intercept\"),\n    blueprinty[[\"age\", \"age_squared\", \"iscustomer\"]],\n    region_dummies\n], axis=1).astype(float)\n\nY = blueprinty[\"patents\"].values\nX_mat = X.values\n\n# 2. Define the negative log-likelihood\ndef neg_poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    lambda_vals = np.exp(X @ beta)\n    return -np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n\n# 3. Optimize\ninit_beta = np.zeros(X.shape[1])\nresult = minimize(neg_poisson_regression_loglikelihood, init_beta, args=(Y, X_mat), method=\"BFGS\")\n\n# Estimated coefficients\nbeta_hat = result.x\n\n# 4. Get standard errors from Hessian\nhessian_inv = result.hess_inv\nse = np.sqrt(np.diag(hessian_inv))\n\n# 5. Create summary table\nsummary_table = pd.DataFrame({\n    \"Coefficient\": beta_hat,\n    \"Std. Error\": se\n}, index=X.columns)\n\nsummary_table\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n1.480059\n1.0\n\n\nage\n38.016417\n1.0\n\n\nage_squared\n1033.539585\n1.0\n\n\niscustomer\n0.553874\n1.0\n\n\nNortheast\n0.640979\n1.0\n\n\nNorthwest\n0.164288\n1.0\n\n\nSouth\n0.181562\n1.0\n\n\nSouthwest\n0.295497\n1.0\n\n\n\n\n\n\n\n\nimport statsmodels.api as sm\n\n# Fit Poisson regression using statsmodels\nglm_model = sm.GLM(Y, X_mat, family=sm.families.Poisson())\nglm_results = glm_model.fit()\n\n# Print summary\nglm_results.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ny\nNo. Observations:\n1500\n\n\nModel:\nGLM\nDf Residuals:\n1492\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3258.1\n\n\nDate:\nWed, 07 May 2025\nDeviance:\n2143.3\n\n\nTime:\n20:47:19\nPearson chi2:\n2.07e+03\n\n\nNo. Iterations:\n5\nPseudo R-squ. (CS):\n0.1360\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-0.5089\n0.183\n-2.778\n0.005\n-0.868\n-0.150\n\n\nx1\n0.1486\n0.014\n10.716\n0.000\n0.121\n0.176\n\n\nx2\n-0.0030\n0.000\n-11.513\n0.000\n-0.003\n-0.002\n\n\nx3\n0.2076\n0.031\n6.719\n0.000\n0.147\n0.268\n\n\nx4\n0.0292\n0.044\n0.669\n0.504\n-0.056\n0.115\n\n\nx5\n-0.0176\n0.054\n-0.327\n0.744\n-0.123\n0.088\n\n\nx6\n0.0566\n0.053\n1.074\n0.283\n-0.047\n0.160\n\n\nx7\n0.0506\n0.047\n1.072\n0.284\n-0.042\n0.143"
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#blueprinty-case-study",
    "href": "projects/HW2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\n\n# Read the blueprinty data\nblueprinty = pd.read_csv(\"blueprinty.csv\")\nblueprinty.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Check unique values for iscustomer\nprint(\"Customer status values:\", blueprinty['iscustomer'].unique())\n\n# Plot histogram\nplt.figure(figsize=(10, 8))\nsns.histplot(data=blueprinty, x=\"patents\", hue=\"iscustomer\", kde=True, multiple=\"stack\")\nplt.title(\"Distribution of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Compare means\nmeans = blueprinty.groupby(\"iscustomer\")[\"patents\"].mean()\nprint(\"Mean number of patents by customer status:\")\nprint(means)\n\nCustomer status values: [0 1]\n\n\n\n\n\n\n\n\n\nMean number of patents by customer status:\niscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\n\n\n\n\nPlots overlapping histograms of number_of_patents by customer_status.\nComputes and prints the mean number_of_patents for each group.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n# Plot region counts by customer status\nplt.figure(figsize=(10, 8))\nsns.countplot(data=blueprinty, x=\"region\", hue=\"iscustomer\")\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\nplt.show()\n\n# Plot age distribution by customer status\nplt.figure(figsize=(10, 8))\nsns.boxplot(data=blueprinty, x=\"iscustomer\", y=\"age\")\nplt.title(\"Age Distribution by Customer Status\")\nplt.xlabel(\"Customer Status\")\nplt.ylabel(\"Age\")\nplt.show()\n\n# Compute mean ages by status\nmean_ages = blueprinty.groupby(\"iscustomer\")[\"age\"].mean()\nprint(\"Mean age by customer status:\")\nprint(mean_ages)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean age by customer status:\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nLet ( Y_1, Y_2, , Y_n ) be independent observations, each distributed as ( Y_i () ).\nThe probability mass function of the Poisson distribution is:\n[ f(Y_i|) = ]\nThe likelihood function for ( n ) observations is:\n[ L(; Y_1, , Y_n) = _{i=1}^{n} = e^{-n} {{i=1}^{n} Y_i} {i=1}{n} ]\nThe log-likelihood is:\n[ L() = -n+ ({i=1}^{n} Y_i) - {i=1}^{n} Y_i! ]\n\n\n\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_loglikelihood(lambd, Y):\n    \"\"\"\n    Compute the log-likelihood of observing data Y under a Poisson model with rate lambda.\n\n    Parameters:\n    - lambd: float, rate parameter (λ) of the Poisson distribution\n    - Y: array-like, observed data\n\n    Returns:\n    - float, the log-likelihood value\n    \"\"\"\n    Y = np.array(Y)\n    if lambd &lt;= 0:\n        return -np.inf  # log-likelihood is undefined for λ ≤ 0\n    return np.sum(Y * np.log(lambd) - lambd - gammaln(Y + 1))\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndf = pd.read_csv(\"blueprinty.csv\")\n\n# Assume the observed count variable is named 'patents'\nY = df['patents'].dropna()\n\n# Range of lambda values to test\nlambda_vals = np.linspace(0.1, 20, 200)\nlog_likelihood_vals = [poisson_loglikelihood(lamb, Y) for lamb in lambda_vals]\n\n# Plot\nplt.figure(figsize=(10, 8))\nplt.plot(lambda_vals, log_likelihood_vals)\nplt.title(\"Log-Likelihood of Poisson Model\")\nplt.xlabel(\"Lambda (λ)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport sympy as sp\n\n# Define symbols\nlmbda, Y1, Y2, Y3 = sp.symbols(\"lambda Y1 Y2 Y3\", positive=True)\n\n# Example: 3 observations (you can generalize this)\nloglik = (-lmbda + Y1 * sp.log(lmbda)) + \\\n         (-lmbda + Y2 * sp.log(lmbda)) + \\\n         (-lmbda + Y3 * sp.log(lmbda))\n\n# Simplify\nloglik = sp.simplify(loglik)\n\n# Take derivative with respect to lambda\ndloglik = sp.diff(loglik, lmbda)\n\n# Solve derivative = 0\nlambda_mle = sp.solve(dloglik, lmbda)\nlambda_mle\n\n[Y1/3 + Y2/3 + Y3/3]\n\n\n\nfrom scipy.optimize import minimize_scalar\n\n# Negative log-likelihood\ndef neg_loglikelihood(lmbda):\n    return -poisson_loglikelihood(lmbda, Y)\n\n# Optimize (bounded to avoid λ ≤ 0)\nresult = minimize_scalar(neg_loglikelihood, bounds=(0.1, 20), method='bounded')\n\n# Output the estimated lambda\nlambda_mle = result.x\nlambda_mle\n\n3.6846666212929713\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\nimport numpy as np\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    \"\"\"\n    Log-likelihood for Poisson regression.\n\n    Parameters:\n    - beta: array-like, coefficients (shape: p,)\n    - Y: array-like, response variable (counts)\n    - X: array-like, design matrix (shape: n x p)\n\n    Returns:\n    - float, total log-likelihood\n    \"\"\"\n    beta = np.array(beta)\n    X = np.array(X)\n    Y = np.array(Y)\n\n    # Compute lambda_i = exp(X_i' * beta)\n    lambda_vals = np.exp(X @ beta)\n\n    # Log-likelihood\n    log_lik = np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n    return log_lik\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom scipy.special import factorial\nfrom numpy.linalg import inv\n\n# 1. Build design matrix X\nblueprinty = blueprinty.copy()\nblueprinty[\"age_squared\"] = blueprinty[\"age\"] ** 2\n\n# Get dummies for region (drop one for reference)\nregion_dummies = pd.get_dummies(blueprinty[\"region\"], drop_first=True)\n\n# Combine features\nX = pd.concat([\n    pd.Series(1, index=blueprinty.index, name=\"intercept\"),\n    blueprinty[[\"age\", \"age_squared\", \"iscustomer\"]],\n    region_dummies\n], axis=1).astype(float)\n\nY = blueprinty[\"patents\"].values\nX_mat = X.values\n\n# 2. Define the negative log-likelihood\ndef neg_poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    lambda_vals = np.exp(X @ beta)\n    return -np.sum(-lambda_vals + Y * np.log(lambda_vals) - np.log(factorial(Y)))\n\n# 3. Optimize\ninit_beta = np.zeros(X.shape[1])\nresult = minimize(neg_poisson_regression_loglikelihood, init_beta, args=(Y, X_mat), method=\"BFGS\")\n\n# Estimated coefficients\nbeta_hat = result.x\n\n# 4. Get standard errors from Hessian\nhessian_inv = result.hess_inv\nse = np.sqrt(np.diag(hessian_inv))\n\n# 5. Create summary table\nsummary_table = pd.DataFrame({\n    \"Coefficient\": beta_hat,\n    \"Std. Error\": se\n}, index=X.columns)\n\nsummary_table\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n1.480059\n1.0\n\n\nage\n38.016417\n1.0\n\n\nage_squared\n1033.539585\n1.0\n\n\niscustomer\n0.553874\n1.0\n\n\nNortheast\n0.640979\n1.0\n\n\nNorthwest\n0.164288\n1.0\n\n\nSouth\n0.181562\n1.0\n\n\nSouthwest\n0.295497\n1.0\n\n\n\n\n\n\n\n\nimport statsmodels.api as sm\n\n# Fit Poisson regression using statsmodels\nglm_model = sm.GLM(Y, X_mat, family=sm.families.Poisson())\nglm_results = glm_model.fit()\n\n# Print summary\nglm_results.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ny\nNo. Observations:\n1500\n\n\nModel:\nGLM\nDf Residuals:\n1492\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3258.1\n\n\nDate:\nWed, 07 May 2025\nDeviance:\n2143.3\n\n\nTime:\n20:47:19\nPearson chi2:\n2.07e+03\n\n\nNo. Iterations:\n5\nPseudo R-squ. (CS):\n0.1360\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-0.5089\n0.183\n-2.778\n0.005\n-0.868\n-0.150\n\n\nx1\n0.1486\n0.014\n10.716\n0.000\n0.121\n0.176\n\n\nx2\n-0.0030\n0.000\n-11.513\n0.000\n-0.003\n-0.002\n\n\nx3\n0.2076\n0.031\n6.719\n0.000\n0.147\n0.268\n\n\nx4\n0.0292\n0.044\n0.669\n0.504\n-0.056\n0.115\n\n\nx5\n-0.0176\n0.054\n-0.327\n0.744\n-0.123\n0.088\n\n\nx6\n0.0566\n0.053\n1.074\n0.283\n-0.047\n0.160\n\n\nx7\n0.0506\n0.047\n1.072\n0.284\n-0.042\n0.143"
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#interpretation-of-poisson-regression-results",
    "href": "projects/HW2/hw2_questions.html#interpretation-of-poisson-regression-results",
    "title": "Poisson Regression Examples",
    "section": "Interpretation of Poisson Regression Results",
    "text": "Interpretation of Poisson Regression Results\nWe fit a Poisson regression model to predict the number of patents using age, customer status, and region.\n\nSummary of Results\n\nModel type: GLM (Poisson family with log link)\nSample size: 1500 observations\nPseudo R² (Cragg & Uhler’s): 0.136 — the model explains about 13.6% of the deviance\n\n\n\nCoefficients and Interpretation\n\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\np-value\nInterpretation\n\n\n\n\nIntercept\n-0.509\n0.183\n0.005\nBaseline log-count of patents; significant\n\n\nAge\n0.149\n0.014\n&lt;0.001\nPositive effect on patent count\n\n\nAge²\n-0.003\n~0.000\n&lt;0.001\nNegative effect; implies diminishing returns with age\n\n\nIs Customer\n0.208\n0.031\n&lt;0.001\nCustomers have ~23% more patents (exp(0.208))\n\n\nRegion dummies\nSmall, non-significant coefficients\n&gt; 0.2\nNot significant\nNo strong regional effect\n\n\n\n\n\nKey Observations\n\nAge is a significant predictor, but due to the negative squared term, the relationship is inverted U-shaped.\nCustomer status has a strong positive effect on patent count.\nRegion variables are not statistically significant, suggesting no major geographic difference in patenting when other variables are controlled for.\n\nThese results align with the MLE estimation performed earlier and validate the implementation."
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#effect-of-blueprintys-software-on-patent-success",
    "href": "projects/HW2/hw2_questions.html#effect-of-blueprintys-software-on-patent-success",
    "title": "Poisson Regression Examples",
    "section": "Effect of Blueprinty’s Software on Patent Success",
    "text": "Effect of Blueprinty’s Software on Patent Success\nWe simulate the effect of becoming a customer using counterfactual prediction. We create two versions of the design matrix:\n\nX_0: where all firms are treated as non-customers (iscustomer = 0)\nX_1: where all firms are treated as customers (iscustomer = 1)\n\nWe use the fitted Poisson regression model to compute predicted patent counts for each firm under both conditions and compute the average treatment effect (ATE) as the difference.\n\nimport statsmodels.api as sm\n\n# Load the dataset\ndf = pd.read_csv(\"blueprinty.csv\")\n\n# Drop missing values\ndf = df.dropna(subset=['patents', 'iscustomer'])\n\n# Define outcome and features\nY = df['patents']\nX = df[['iscustomer']]  # Add more covariates if needed\n\n# Add intercept\nX = sm.add_constant(X)\n\n# Fit Poisson regression\npoisson_model = sm.GLM(Y, X, family=sm.families.Poisson()).fit()\n\n# Create X_0 and X_1\nX_0 = X.copy()\nX_0['iscustomer'] = 0\n\nX_1 = X.copy()\nX_1['iscustomer'] = 1\n\n# Predict\ny_pred_0 = poisson_model.predict(X_0)\ny_pred_1 = poisson_model.predict(X_1)\n\n# Calculate average treatment effect\naverage_effect = (y_pred_1 - y_pred_0).mean()\naverage_effect\n\n0.6600433754518399"
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#airbnb-case-study",
    "href": "projects/HW2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not"
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#airbnb-modeling-the-number-of-reviews-as-a-proxy-for-bookings",
    "href": "projects/HW2/hw2_questions.html#airbnb-modeling-the-number-of-reviews-as-a-proxy-for-bookings",
    "title": "Poisson Regression Examples",
    "section": "Airbnb: Modeling the Number of Reviews as a Proxy for Bookings",
    "text": "Airbnb: Modeling the Number of Reviews as a Proxy for Bookings\nWe use the number of reviews as a proxy for the number of bookings. Below, we conduct EDA, handle missing values, and fit a Poisson regression to model the number of reviews.\n\n\nStep 1: Load and Clean the Data\n\nimport pandas as pd\n\n# Load the dataset\ndf = pd.read_csv(\"airbnb.csv\")\n\n# Preview the data\ndf.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\n# Check missing values\ndf.isnull().sum().sort_values(ascending=False)\n\nreview_scores_value          10256\nreview_scores_location       10254\nreview_scores_cleanliness    10195\nbathrooms                      160\nbedrooms                        76\nhost_since                      35\nUnnamed: 0                       0\nid                               0\ndays                             0\nlast_scraped                     0\nroom_type                        0\nprice                            0\nnumber_of_reviews                0\ninstant_bookable                 0\ndtype: int64\n\n\n\nimport numpy as np\n\n# Convert dates\ndf['last_scraped'] = pd.to_datetime(df['last_scraped'], errors='coerce')\ndf['host_since'] = pd.to_datetime(df['host_since'], errors='coerce')\n\n# Compute 'days' active\ndf['days'] = (df['last_scraped'] - df['host_since']).dt.days\n\n# Convert 'instant_bookable' to binary\ndf['instant_bookable'] = df['instant_bookable'].map({'t': 1, 'f': 0})\n\n# Keep relevant columns\nrelevant_cols = [\n    'number_of_reviews', 'room_type', 'bathrooms', 'bedrooms',\n    'price', 'review_scores_cleanliness', 'review_scores_location',\n    'review_scores_value', 'instant_bookable', 'days'\n]\n\ndf_clean = df[relevant_cols].dropna()\n\n# Check cleaned data shape\ndf_clean.shape\n\n(30140, 10)\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Summary stats\ndisplay(df_clean.describe())\n\n# Plot number_of_reviews vs. numeric predictors\nnumeric_vars = [\n    'price', 'bathrooms', 'bedrooms', 'days',\n    'review_scores_cleanliness', 'review_scores_location',\n    'review_scores_value'\n]\n\nfor var in numeric_vars:\n    plt.figure(figsize=(10, 8))\n    sns.scatterplot(data=df_clean, x=var, y='number_of_reviews', alpha=0.5)\n    plt.title(f'Number of Reviews vs {var}')\n    plt.xlabel(var)\n    plt.ylabel('Number of Reviews')\n    plt.grid(True)\n    plt.show()\n\n\n\n\n\n\n\n\nnumber_of_reviews\nbathrooms\nbedrooms\nprice\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\ndays\n\n\n\n\ncount\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n30140.000000\n\n\nmean\n21.168115\n1.122213\n1.151460\n140.211546\n9.201758\n9.415428\n9.334041\n0.196151\n1112.048275\n\n\nstd\n32.004711\n0.385031\n0.699039\n188.437967\n1.114472\n0.843181\n0.900595\n0.397091\n644.430782\n\n\nmin\n1.000000\n0.000000\n0.000000\n10.000000\n2.000000\n2.000000\n2.000000\n0.000000\n7.000000\n\n\n25%\n3.000000\n1.000000\n1.000000\n70.000000\n9.000000\n9.000000\n9.000000\n0.000000\n584.000000\n\n\n50%\n8.000000\n1.000000\n1.000000\n103.000000\n10.000000\n10.000000\n10.000000\n0.000000\n1040.000000\n\n\n75%\n26.000000\n1.000000\n1.000000\n169.000000\n10.000000\n10.000000\n10.000000\n0.000000\n1591.000000\n\n\nmax\n421.000000\n6.000000\n10.000000\n10000.000000\n10.000000\n10.000000\n10.000000\n1.000000\n3317.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\n# Load dataset\ndf = pd.read_csv(\"airbnb.csv\")\n\n# Convert date columns and calculate 'days' (not used in this model)\ndf['last_scraped'] = pd.to_datetime(df['last_scraped'], errors='coerce')\ndf['host_since'] = pd.to_datetime(df['host_since'], errors='coerce')\ndf['days'] = (df['last_scraped'] - df['host_since']).dt.days\n\n# Convert 'instant_bookable' to binary\ndf['instant_bookable'] = df['instant_bookable'].map({'t': 1, 'f': 0})\n\n# Select relevant columns and drop missing values\nairbnb_clean = df[[\n    'number_of_reviews', 'room_type', 'bathrooms', 'bedrooms', 'price',\n    'review_scores_cleanliness', 'review_scores_location',\n    'review_scores_value', 'instant_bookable'\n]].dropna()\n\n# Create dummy variables for 'room_type' (drop first to avoid multicollinearity)\nroom_dummies = pd.get_dummies(airbnb_clean['room_type'], drop_first=True)\n\n# Build design matrix X\nX = pd.concat([\n    airbnb_clean[['bathrooms', 'bedrooms', 'price',\n                  'review_scores_cleanliness', 'review_scores_location',\n                  'review_scores_value', 'instant_bookable']],\n    room_dummies\n], axis=1)\n\n# Convert any boolean columns to integers\nX = X.astype(float)\n\n# Add intercept\nX = sm.add_constant(X)\n\n# Define outcome variable\nY = airbnb_clean['number_of_reviews']\n\n# Fit Poisson regression model\npoisson_model = sm.GLM(Y, X, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\n\n# Display model summary\npoisson_results.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nnumber_of_reviews\nNo. Observations:\n30160\n\n\nModel:\nGLM\nDf Residuals:\n30150\n\n\nModel Family:\nPoisson\nDf Model:\n9\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-5.2900e+05\n\n\nDate:\nWed, 07 May 2025\nDeviance:\n9.3653e+05\n\n\nTime:\n20:47:20\nPearson chi2:\n1.41e+06\n\n\nNo. Iterations:\n6\nPseudo R-squ. (CS):\n0.5649\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n3.5725\n0.016\n223.215\n0.000\n3.541\n3.604\n\n\nbathrooms\n-0.1240\n0.004\n-33.091\n0.000\n-0.131\n-0.117\n\n\nbedrooms\n0.0749\n0.002\n37.698\n0.000\n0.071\n0.079\n\n\nprice\n-1.435e-05\n8.3e-06\n-1.729\n0.084\n-3.06e-05\n1.92e-06\n\n\nreview_scores_cleanliness\n0.1132\n0.001\n75.820\n0.000\n0.110\n0.116\n\n\nreview_scores_location\n-0.0768\n0.002\n-47.796\n0.000\n-0.080\n-0.074\n\n\nreview_scores_value\n-0.0915\n0.002\n-50.902\n0.000\n-0.095\n-0.088\n\n\ninstant_bookable\n0.3344\n0.003\n115.748\n0.000\n0.329\n0.340\n\n\nPrivate room\n-0.0145\n0.003\n-5.310\n0.000\n-0.020\n-0.009\n\n\nShared room\n-0.2519\n0.009\n-29.229\n0.000\n-0.269\n-0.235\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\n# Get exponentiated coefficients and confidence intervals\ncoef = poisson_results.params\nconf_int = poisson_results.conf_int()\nexp_coef = np.exp(coef)\nexp_conf_int = np.exp(conf_int)\n\n# Create summary DataFrame\neffects_df = pd.DataFrame({\n    \"Variable\": coef.index,\n    \"Exp(Coefficient)\": exp_coef.round(3),\n    \"95% CI Lower\": np.exp(conf_int[0]).round(3),\n    \"95% CI Upper\": np.exp(conf_int[1]).round(3),\n    \"Interpretation\": exp_coef.apply(lambda x: f\"{(x - 1) * 100:.1f}% change in expected reviews\")\n})\n\n# Display table\neffects_df.reset_index(drop=True, inplace=True)\neffects_df\n\n\n\n\n\n\n\n\nVariable\nExp(Coefficient)\n95% CI Lower\n95% CI Upper\nInterpretation\n\n\n\n\n0\nconst\n35.605\n34.505\n36.740\n3460.5% change in expected reviews\n\n\n1\nbathrooms\n0.883\n0.877\n0.890\n-11.7% change in expected reviews\n\n\n2\nbedrooms\n1.078\n1.074\n1.082\n7.8% change in expected reviews\n\n\n3\nprice\n1.000\n1.000\n1.000\n-0.0% change in expected reviews\n\n\n4\nreview_scores_cleanliness\n1.120\n1.117\n1.123\n12.0% change in expected reviews\n\n\n5\nreview_scores_location\n0.926\n0.923\n0.929\n-7.4% change in expected reviews\n\n\n6\nreview_scores_value\n0.913\n0.909\n0.916\n-8.7% change in expected reviews\n\n\n7\ninstant_bookable\n1.397\n1.389\n1.405\n39.7% change in expected reviews\n\n\n8\nPrivate room\n0.986\n0.980\n0.991\n-1.4% change in expected reviews\n\n\n9\nShared room\n0.777\n0.764\n0.791\n-22.3% change in expected reviews"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html",
    "href": "projects/HW3/hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "projects/HW3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#simulate-conjoint-data",
    "href": "projects/HW3/hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\n\n# Set seed for reproducibility\nnp.random.seed(123)\n\n# Define attributes\nbrands = ['N', 'P', 'H']  # Netflix, Prime, Hulu\nads = ['Yes', 'No']\nprices = np.arange(8, 33, 4)  # 8 to 32 inclusive\n\n# Generate all possible profiles\nimport itertools\nprofiles = pd.DataFrame(list(itertools.product(brands, ads, prices)), columns=['brand', 'ad', 'price'])\nm = profiles.shape[0]\n\n# Define part-worth utilities\nb_util = {'N': 1.0, 'P': 0.5, 'H': 0.0}\na_util = {'Yes': -0.8, 'No': 0.0}\np_util = lambda p: -0.1 * p\n\n# Simulation settings\nn_peeps = 100\nn_tasks = 10\nn_alts = 3\n\n# Function to simulate one respondent's data\ndef sim_one(resp_id):\n    tasks = []\n    for task in range(1, n_tasks + 1):\n        sampled = profiles.sample(n=n_alts, replace=False).copy()\n        sampled['resp'] = resp_id\n        sampled['task'] = task\n\n        # Compute deterministic utility\n        sampled['v'] = (\n            sampled['brand'].map(b_util) +\n            sampled['ad'].map(a_util) +\n            p_util(sampled['price'])\n        ).round(10)\n\n        # Add Gumbel noise (Type I extreme value)\n        sampled['e'] = -np.log(-np.log(np.random.uniform(size=n_alts)))\n        sampled['u'] = sampled['v'] + sampled['e']\n\n        # Identify chosen alternative\n        sampled['choice'] = (sampled['u'] == sampled['u'].max()).astype(int)\n\n        tasks.append(sampled[['resp', 'task', 'brand', 'ad', 'price', 'choice']])\n    return pd.concat(tasks, ignore_index=True)\n\n# Simulate data for all respondents\nconjoint_data = pd.concat([sim_one(i) for i in range(1, n_peeps + 1)], ignore_index=True)\n\n# View first few rows\nconjoint_data.head()\n\n\n\n\n\n\n\n\nresp\ntask\nbrand\nad\nprice\nchoice\n\n\n\n\n0\n1\n1\nP\nNo\n32\n0\n\n\n1\n1\n1\nN\nNo\n28\n0\n\n\n2\n1\n1\nN\nNo\n24\n1\n\n\n3\n1\n2\nH\nNo\n28\n0\n\n\n4\n1\n2\nH\nNo\n8\n1"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#preparing-the-data-for-estimation",
    "href": "projects/HW3/hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\n\nimport pandas as pd\n\n# Load the conjoint data\nconjoint_data = pd.read_csv(\"conjoint_data.csv\")\n\n# One-hot encode categorical variables (Hulu and Ad-Free as reference levels)\nconjoint_prepped = pd.get_dummies(conjoint_data, columns=[\"brand\", \"ad\"], drop_first=True)\n\n# Sort the data to preserve the order by respondent and task\nconjoint_prepped = conjoint_prepped.sort_values(by=[\"resp\", \"task\"]).reset_index(drop=True)\n\n# Create the design matrix (X) and the target vector (y)\nX = conjoint_prepped[[\"brand_N\", \"brand_P\", \"ad_Yes\", \"price\"]]\ny = conjoint_prepped[\"choice\"]\n\n# Optionally combine X and y with respondent/task info for review\nconjoint_ready = pd.concat([conjoint_prepped[[\"resp\", \"task\"]], X, y], axis=1)\n\n# Display first few rows\nconjoint_ready.head()\n\n\n\n\n\n\n\n\nresp\ntask\nbrand_N\nbrand_P\nad_Yes\nprice\nchoice\n\n\n\n\n0\n1\n1\nTrue\nFalse\nTrue\n28\n1\n\n\n1\n1\n1\nFalse\nFalse\nTrue\n16\n0\n\n\n2\n1\n1\nFalse\nTrue\nTrue\n16\n0\n\n\n3\n1\n2\nTrue\nFalse\nTrue\n32\n0\n\n\n4\n1\n2\nFalse\nTrue\nTrue\n16\n1"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "projects/HW3/hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\n\n# Step 1: Define the MNL log-likelihood function\ndef mnl_log_likelihood(beta, X, y, group_size=3):\n    beta = np.asarray(beta, dtype=np.float64)\n    X_np = np.asarray(X, dtype=np.float64)\n    y_np = np.asarray(y, dtype=np.int64)\n\n    # Compute utilities and reshape into (n_tasks, n_alternatives)\n    Xb = X_np @ beta\n    Xb = Xb.reshape(-1, group_size)\n    y_np = y_np.reshape(-1, group_size)\n\n    # Compute softmax probabilities\n    exp_Xb = np.exp(Xb)\n    probs = exp_Xb / np.sum(exp_Xb, axis=1, keepdims=True)\n\n    # Compute log-likelihood (only for chosen alternatives)\n    chosen_probs = np.sum(probs * y_np, axis=1)\n    log_likelihood = np.sum(np.log(chosen_probs))\n\n    return -log_likelihood  # for minimization\n\n\n# Step 2: Run MLE using scipy.optimize.minimize\ninit_params = np.zeros(X.shape[1])  # starting at 0s\n\nresult = minimize(\n    mnl_log_likelihood,\n    init_params,\n    args=(X, y),\n    method='BFGS',\n    options={'disp': True}\n)\n\n# Extract estimates\nbeta_hat = result.x\nhessian_inv = result.hess_inv  # Hessian inverse for variance\n\nOptimization terminated successfully.\n         Current function value: 879.855368\n         Iterations: 12\n         Function evaluations: 85\n         Gradient evaluations: 17\n\n\n\n# Step 3: Standard errors and confidence intervals\nse = np.sqrt(np.diag(hessian_inv))\nz = 1.96  # for 95% CI\nci_lower = beta_hat - z * se\nci_upper = beta_hat + z * se\n\n# Step 4: Present results in a DataFrame\nparam_names = ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price']\nresults = pd.DataFrame({\n    'Parameter': param_names,\n    'Estimate': beta_hat,\n    'Std. Error': se,\n    '95% CI Lower': ci_lower,\n    '95% CI Upper': ci_upper\n})\n\nresults\n\n\n\n\n\n\n\n\nParameter\nEstimate\nStd. Error\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\nbeta_netflix\n0.941195\n0.114679\n0.716425\n1.165965\n\n\n1\nbeta_prime\n0.501616\n0.120757\n0.264932\n0.738299\n\n\n2\nbeta_ads\n-0.731994\n0.088476\n-0.905408\n-0.558580\n\n\n3\nbeta_price\n-0.099480\n0.006357\n-0.111940\n-0.087021"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#estimation-via-maximum-likelihood-1",
    "href": "projects/HW3/hw3_questions.html#estimation-via-maximum-likelihood-1",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\n\n# Step 1: Define the MNL log-likelihood function\ndef mnl_log_likelihood(beta, X, y, group_size=3):\n    beta = np.asarray(beta, dtype=np.float64)\n    X_np = np.asarray(X, dtype=np.float64)\n    y_np = np.asarray(y, dtype=np.int64)\n\n    # Compute utilities and reshape into (n_tasks, n_alternatives)\n    Xb = X_np @ beta\n    Xb = Xb.reshape(-1, group_size)\n    y_np = y_np.reshape(-1, group_size)\n\n    # Compute softmax probabilities\n    exp_Xb = np.exp(Xb)\n    probs = exp_Xb / np.sum(exp_Xb, axis=1, keepdims=True)\n\n    # Compute log-likelihood (only for chosen alternatives)\n    chosen_probs = np.sum(probs * y_np, axis=1)\n    log_likelihood = np.sum(np.log(chosen_probs))\n\n    return -log_likelihood  # for minimization\n\n\n# Step 2: Run MLE using scipy.optimize.minimize\ninit_params = np.zeros(X.shape[1])  # starting at 0s\n\nresult = minimize(\n    mnl_log_likelihood,\n    init_params,\n    args=(X, y),\n    method='BFGS',\n    options={'disp': True}\n)\n\n# Extract estimates\nbeta_hat = result.x\nhessian_inv = result.hess_inv  # Hessian inverse for variance\n\nOptimization terminated successfully.\n         Current function value: 879.855368\n         Iterations: 12\n         Function evaluations: 85\n         Gradient evaluations: 17\n\n\n\n# Step 3: Standard errors and confidence intervals\nse = np.sqrt(np.diag(hessian_inv))\nz = 1.96  # for 95% CI\nci_lower = beta_hat - z * se\nci_upper = beta_hat + z * se\n\n# Step 4: Present results in a DataFrame\nparam_names = ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price']\nresults = pd.DataFrame({\n    'Parameter': param_names,\n    'Estimate': beta_hat,\n    'Std. Error': se,\n    '95% CI Lower': ci_lower,\n    '95% CI Upper': ci_upper\n})\n\nresults\n\n\n\n\n\n\n\n\nParameter\nEstimate\nStd. Error\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\nbeta_netflix\n0.941195\n0.114679\n0.716425\n1.165965\n\n\n1\nbeta_prime\n0.501616\n0.120757\n0.264932\n0.738299\n\n\n2\nbeta_ads\n-0.731994\n0.088476\n-0.905408\n-0.558580\n\n\n3\nbeta_price\n-0.099480\n0.006357\n-0.111940\n-0.087021"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#estimation-via-bayesian-methods",
    "href": "projects/HW3/hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\n\nimport numpy as np\nimport pandas as pd\n\n# Define log-prior function\ndef log_prior(beta):\n    # Priors: N(0,5) for first 3 (binary vars), N(0,1) for price\n    binary_log_priors = -0.5 * (beta[:3] ** 2) / 5 - 0.5 * np.log(2 * np.pi * 5)\n    price_log_prior = -0.5 * (beta[3] ** 2) / 1 - 0.5 * np.log(2 * np.pi * 1)\n    return np.sum(binary_log_priors) + price_log_prior\n\n# Log-posterior function = log-likelihood + log-prior\ndef log_posterior(beta, X, y, group_size=3):\n    return -mnl_log_likelihood(beta, X, y, group_size) + log_prior(beta)\n\n# Metropolis-Hastings MCMC\ndef metropolis_sampler(log_post_func, X, y, n_iter=11000, burn_in=1000, proposal_sd=[0.05, 0.05, 0.05, 0.005]):\n    d = X.shape[1]\n    samples = np.zeros((n_iter, d))\n    current_beta = np.zeros(d)\n    current_log_post = log_post_func(current_beta, X, y)\n\n    for i in range(n_iter):\n        # Propose new beta from independent normal proposals\n        proposal = current_beta + np.random.normal(loc=0, scale=proposal_sd)\n        proposal_log_post = log_post_func(proposal, X, y)\n\n        # Acceptance probability\n        accept_prob = np.exp(proposal_log_post - current_log_post)\n        if np.random.rand() &lt; accept_prob:\n            current_beta = proposal\n            current_log_post = proposal_log_post\n\n        samples[i] = current_beta\n\n    return samples[burn_in:]  # remove burn-in\n\n\n# Run MCMC\nposterior_samples = metropolis_sampler(log_posterior, X, y, n_iter=11000, burn_in=1000)\n\n# Summarize posterior\nparam_names = ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price']\nsummary = pd.DataFrame({\n    'Parameter': param_names,\n    'Mean': posterior_samples.mean(axis=0),\n    'Std. Dev.': posterior_samples.std(axis=0),\n    '2.5%': np.percentile(posterior_samples, 2.5, axis=0),\n    '97.5%': np.percentile(posterior_samples, 97.5, axis=0)\n})\nsummary\n\n\n\n\n\n\n\n\nParameter\nMean\nStd. Dev.\n2.5%\n97.5%\n\n\n\n\n0\nbeta_netflix\n0.933779\n0.105876\n0.725049\n1.140153\n\n\n1\nbeta_prime\n0.490407\n0.107846\n0.280290\n0.701549\n\n\n2\nbeta_ads\n-0.726319\n0.088917\n-0.895791\n-0.548707\n\n\n3\nbeta_price\n-0.099618\n0.006388\n-0.112351\n-0.087293\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Select parameter index (0: beta_netflix, 1: beta_prime, 2: beta_ads, 3: beta_price)\nparam_index = 3\nparam_name = 'beta_price'\nsamples = posterior_samples[:, param_index]\n\n# Trace plot\nplt.figure(figsize=(10, 4))\nplt.plot(samples)\nplt.title(f\"Trace Plot for {param_name}\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Parameter Value\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# Histogram of posterior samples\nplt.figure(figsize=(8, 6))\nplt.hist(samples, bins=40, edgecolor='black', density=True)\nplt.title(f\"Posterior Distribution for {param_name}\")\nplt.xlabel(\"Parameter Value\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# Bayesian summary\nbayes_summary = pd.DataFrame({\n    'Parameter': ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price'],\n    'Bayes Mean': posterior_samples.mean(axis=0),\n    'Bayes Std. Dev.': posterior_samples.std(axis=0),\n    'Bayes 2.5%': np.percentile(posterior_samples, 2.5, axis=0),\n    'Bayes 97.5%': np.percentile(posterior_samples, 97.5, axis=0)\n})\n\n# Merge with MLE results\ncomparison = results.merge(bayes_summary, on='Parameter')\n\n# Show comparison\ncomparison[['Parameter', 'Estimate', 'Std. Error', '95% CI Lower', '95% CI Upper',\n            'Bayes Mean', 'Bayes Std. Dev.', 'Bayes 2.5%', 'Bayes 97.5%']]\n\n\n\n\n\n\n\n\nParameter\nEstimate\nStd. Error\n95% CI Lower\n95% CI Upper\nBayes Mean\nBayes Std. Dev.\nBayes 2.5%\nBayes 97.5%\n\n\n\n\n0\nbeta_netflix\n0.941195\n0.114679\n0.716425\n1.165965\n0.933779\n0.105876\n0.725049\n1.140153\n\n\n1\nbeta_prime\n0.501616\n0.120757\n0.264932\n0.738299\n0.490407\n0.107846\n0.280290\n0.701549\n\n\n2\nbeta_ads\n-0.731994\n0.088476\n-0.905408\n-0.558580\n-0.726319\n0.088917\n-0.895791\n-0.548707\n\n\n3\nbeta_price\n-0.099480\n0.006357\n-0.111940\n-0.087021\n-0.099618\n0.006388\n-0.112351\n-0.087293"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#estimation-via-bayesian-methods-1",
    "href": "projects/HW3/hw3_questions.html#estimation-via-bayesian-methods-1",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\n\nimport numpy as np\nimport pandas as pd\n\n# Define log-prior function\ndef log_prior(beta):\n    # Priors: N(0,5) for first 3 (binary vars), N(0,1) for price\n    binary_log_priors = -0.5 * (beta[:3] ** 2) / 5 - 0.5 * np.log(2 * np.pi * 5)\n    price_log_prior = -0.5 * (beta[3] ** 2) / 1 - 0.5 * np.log(2 * np.pi * 1)\n    return np.sum(binary_log_priors) + price_log_prior\n\n# Log-posterior function = log-likelihood + log-prior\ndef log_posterior(beta, X, y, group_size=3):\n    return -mnl_log_likelihood(beta, X, y, group_size) + log_prior(beta)\n\n# Metropolis-Hastings MCMC\ndef metropolis_sampler(log_post_func, X, y, n_iter=11000, burn_in=1000, proposal_sd=[0.05, 0.05, 0.05, 0.005]):\n    d = X.shape[1]\n    samples = np.zeros((n_iter, d))\n    current_beta = np.zeros(d)\n    current_log_post = log_post_func(current_beta, X, y)\n\n    for i in range(n_iter):\n        # Propose new beta from independent normal proposals\n        proposal = current_beta + np.random.normal(loc=0, scale=proposal_sd)\n        proposal_log_post = log_post_func(proposal, X, y)\n\n        # Acceptance probability\n        accept_prob = np.exp(proposal_log_post - current_log_post)\n        if np.random.rand() &lt; accept_prob:\n            current_beta = proposal\n            current_log_post = proposal_log_post\n\n        samples[i] = current_beta\n\n    return samples[burn_in:]  # remove burn-in\n\n\n# Run MCMC\nposterior_samples = metropolis_sampler(log_posterior, X, y, n_iter=11000, burn_in=1000)\n\n# Summarize posterior\nparam_names = ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price']\nsummary = pd.DataFrame({\n    'Parameter': param_names,\n    'Mean': posterior_samples.mean(axis=0),\n    'Std. Dev.': posterior_samples.std(axis=0),\n    '2.5%': np.percentile(posterior_samples, 2.5, axis=0),\n    '97.5%': np.percentile(posterior_samples, 97.5, axis=0)\n})\nsummary\n\n\n\n\n\n\n\n\nParameter\nMean\nStd. Dev.\n2.5%\n97.5%\n\n\n\n\n0\nbeta_netflix\n0.933779\n0.105876\n0.725049\n1.140153\n\n\n1\nbeta_prime\n0.490407\n0.107846\n0.280290\n0.701549\n\n\n2\nbeta_ads\n-0.726319\n0.088917\n-0.895791\n-0.548707\n\n\n3\nbeta_price\n-0.099618\n0.006388\n-0.112351\n-0.087293\n\n\n\n\n\n\n\ntodo: for at least one of the 4 parameters, show the trace plot of the algorithm, as well as the histogram of the posterior distribution.\n\nimport matplotlib.pyplot as plt\n\n# Select parameter index (0: beta_netflix, 1: beta_prime, 2: beta_ads, 3: beta_price)\nparam_index = 3\nparam_name = 'beta_price'\nsamples = posterior_samples[:, param_index]\n\n# Trace plot\nplt.figure(figsize=(10, 4))\nplt.plot(samples)\nplt.title(f\"Trace Plot for {param_name}\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Parameter Value\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# Histogram of posterior samples\nplt.figure(figsize=(8, 6))\nplt.hist(samples, bins=40, edgecolor='black', density=True)\nplt.title(f\"Posterior Distribution for {param_name}\")\nplt.xlabel(\"Parameter Value\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\ntodo: report the 4 posterior means, standard deviations, and 95% credible intervals and compare them to your results from the Maximum Likelihood approach.\n\n# Bayesian summary\nbayes_summary = pd.DataFrame({\n    'Parameter': ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price'],\n    'Bayes Mean': posterior_samples.mean(axis=0),\n    'Bayes Std. Dev.': posterior_samples.std(axis=0),\n    'Bayes 2.5%': np.percentile(posterior_samples, 2.5, axis=0),\n    'Bayes 97.5%': np.percentile(posterior_samples, 97.5, axis=0)\n})\n\n# Merge with MLE results\ncomparison = results.merge(bayes_summary, on='Parameter')\n\n# Show comparison\ncomparison[['Parameter', 'Estimate', 'Std. Error', '95% CI Lower', '95% CI Upper',\n            'Bayes Mean', 'Bayes Std. Dev.', 'Bayes 2.5%', 'Bayes 97.5%']]\n\n\n\n\n\n\n\n\nParameter\nEstimate\nStd. Error\n95% CI Lower\n95% CI Upper\nBayes Mean\nBayes Std. Dev.\nBayes 2.5%\nBayes 97.5%\n\n\n\n\n0\nbeta_netflix\n0.941195\n0.114679\n0.716425\n1.165965\n0.933779\n0.105876\n0.725049\n1.140153\n\n\n1\nbeta_prime\n0.501616\n0.120757\n0.264932\n0.738299\n0.490407\n0.107846\n0.280290\n0.701549\n\n\n2\nbeta_ads\n-0.731994\n0.088476\n-0.905408\n-0.558580\n-0.726319\n0.088917\n-0.895791\n-0.548707\n\n\n3\nbeta_price\n-0.099480\n0.006357\n-0.111940\n-0.087021\n-0.099618\n0.006388\n-0.112351\n-0.087293"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#discussion",
    "href": "projects/HW3/hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\nIf we had not simulated the data and instead estimated the model from real survey responses, we would interpret the parameter estimates as reflecting consumer preferences for different streaming service attributes.\n\nThe fact that \\(\\beta_\\text{Netflix} &gt; \\beta_\\text{Prime}\\) implies that, on average, respondents prefer Netflix over Amazon Prime when all other attributes (ads and price) are held constant. This aligns with common perceptions of Netflix as a more dominant or desirable streaming brand.\nA negative coefficient for price (\\(\\beta_\\text{price} &lt; 0\\)) makes intuitive and economic sense: as price increases, utility (and hence the probability of choosing an option) decreases. This confirms price sensitivity, a key aspect of consumer choice modeling.\nThe magnitude of \\(\\beta_\\text{ads}\\) (likely negative) reflects disutility from included advertisements. A larger negative value would suggest that respondents strongly prefer ad-free experiences.\n\nOverall, the signs and relative sizes of the parameters are consistent with rational consumer behavior. The comparison between the MLE and Bayesian results shows that both approaches yield similar inference, with Bayesian methods also providing full posterior distributions for the parameters."
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#additional-discussion-extending-to-a-multi-level-model",
    "href": "projects/HW3/hw3_questions.html#additional-discussion-extending-to-a-multi-level-model",
    "title": "Multinomial Logit Model",
    "section": "Additional Discussion: Extending to a Multi-Level Model",
    "text": "Additional Discussion: Extending to a Multi-Level Model\nTo simulate data from — and estimate parameters of — a multi-level (random parameter or hierarchical) MNL model, the key conceptual change is to allow individual-level heterogeneity in preferences.\n\nSimulation Changes:\nIn the current model, all respondents share the same coefficients (β) for attributes. To simulate data from a hierarchical model, we would: - Draw each respondent’s coefficients from a population distribution.\nFor example: \\[\n  \\beta_i \\sim \\mathcal{N}(\\mu, \\Sigma)\n  \\] where \\(\\mu\\) is the average preference vector across all respondents, and \\(\\Sigma\\) is the covariance matrix capturing variability in preferences across individuals. - Then simulate each respondent’s choices using their own \\(\\beta_i\\).\n\n\nEstimation Changes:\nTo estimate such a model: - You can no longer rely on a single likelihood function over one shared \\(\\beta\\). - Instead, use Bayesian hierarchical modeling, where: - Each respondent has their own \\(\\beta_i\\). - The \\(\\beta_i\\)’s are modeled as coming from a population-level distribution with unknown hyperparameters \\((\\mu, \\Sigma)\\). - Estimation typically requires MCMC sampling methods such as Gibbs sampling or Hamiltonian Monte Carlo (e.g., via PyMC, Stan, or NUTS samplers).\nThis hierarchical structure allows the model to better fit real-world conjoint data, where preferences vary significantly across individuals."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html",
    "href": "projects/HW4/hw4_questions.html",
    "title": "Machine Learning Applications in Marketing",
    "section": "",
    "text": "Note: Have included both from each section for analysis [1a, 1b, AND 2a, 2b]."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#a.-k-means",
    "href": "projects/HW4/hw4_questions.html#a.-k-means",
    "title": "Machine Learning Applications in Marketing",
    "section": "1a. K-Means",
    "text": "1a. K-Means\nWe will implement the K-Means algorithm from scratch and compare the results to sklearn’s built-in KMeans. We use bill length and flipper length as input variables.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n# Load the dataset\npenguins = pd.read_csv(\"palmer_penguins.csv\")\n\n# Filter and select required columns\nX = penguins[['bill_length_mm', 'flipper_length_mm']].dropna().values\n\n# Plot the initial data\nplt.figure(figsize=(10, 8))\nplt.scatter(X[:, 0], X[:, 1], c='gray')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Flipper Length (mm)')\nplt.title('Initial Data - Palmer Penguins')\nplt.show()\n\n\n\n\n\n\n\n\n\nCustom K-Means Algorithm\n\ndef initialize_centroids(X, k):\n    np.random.seed(42)\n    indices = np.random.choice(len(X), k, replace=False)\n    return X[indices]\n\ndef assign_clusters(X, centroids):\n    distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n    return np.argmin(distances, axis=1)\n\ndef update_centroids(X, labels, k):\n    return np.array([X[labels == i].mean(axis=0) for i in range(k)])\n\ndef has_converged(old_centroids, new_centroids, tol=1e-4):\n    return np.all(np.linalg.norm(new_centroids - old_centroids, axis=1) &lt; tol)\n\ndef kmeans_custom(X, k, max_iters=100):\n    centroids = initialize_centroids(X, k)\n    for i in range(max_iters):\n        labels = assign_clusters(X, centroids)\n        new_centroids = update_centroids(X, labels, k)\n        \n        # Plot iteration\n        plt.figure(figsize=(10, 8))\n        plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.6)\n        plt.scatter(new_centroids[:, 0], new_centroids[:, 1], \n                    c='red', marker='X', s=200, label='Centroids')\n        plt.xlabel('Bill Length (mm)')\n        plt.ylabel('Flipper Length (mm)')\n        plt.title(f'Custom K-Means Iteration {i+1}')\n        plt.legend()\n        plt.show()\n\n        if has_converged(centroids, new_centroids):\n            break\n        centroids = new_centroids\n    return labels, centroids\n\n\n\nRun Custom K-Means\n\n# Set number of clusters\nk = 3\n\n# Apply custom K-Means\ncustom_labels, custom_centroids = kmeans_custom(X, k)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompare with Built-in KMeans\n\n# Fit built-in KMeans\nkmeans = KMeans(n_clusters=k, random_state=42)\nbuiltin_labels = kmeans.fit_predict(X)\n\n# Plot comparison\nplt.figure(figsize=(10, 8))\nplt.scatter(X[:, 0], X[:, 1], c=builtin_labels, cmap='viridis', alpha=0.6)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n            c='red', marker='X', s=200, label='Centroids')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Flipper Length (mm)')\nplt.title('Built-in KMeans Result')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#a.-k-means-clustering-palmer-penguins",
    "href": "projects/HW4/hw4_questions.html#a.-k-means-clustering-palmer-penguins",
    "title": "Machine Learning Applications in Marketing",
    "section": "1a. K-Means Clustering – Palmer Penguins",
    "text": "1a. K-Means Clustering – Palmer Penguins\nWe will implement the K-Means algorithm from scratch and compare the results to sklearn’s built-in KMeans. We use bill length and flipper length as input variables.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n# Load the dataset\npenguins = pd.read_csv(\"palmer_penguins.csv\")\n\n# Filter and select required columns\nX = penguins[['bill_length_mm', 'flipper_length_mm']].dropna().values\n\n# Plot the initial data\nplt.figure(figsize=(10, 8))\nplt.scatter(X[:, 0], X[:, 1], c='gray')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Flipper Length (mm)')\nplt.title('Initial Data - Palmer Penguins')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCustom K-Means Algorithm\n\ndef initialize_centroids(X, k):\n    np.random.seed(42)\n    indices = np.random.choice(len(X), k, replace=False)\n    return X[indices]\n\ndef assign_clusters(X, centroids):\n    distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n    return np.argmin(distances, axis=1)\n\ndef update_centroids(X, labels, k):\n    return np.array([X[labels == i].mean(axis=0) for i in range(k)])\n\ndef has_converged(old_centroids, new_centroids, tol=1e-4):\n    return np.all(np.linalg.norm(new_centroids - old_centroids, axis=1) &lt; tol)\n\ndef kmeans_custom(X, k, max_iters=100):\n    centroids = initialize_centroids(X, k)\n    for i in range(max_iters):\n        labels = assign_clusters(X, centroids)\n        new_centroids = update_centroids(X, labels, k)\n        \n        # Plot iteration\n        plt.figure(figsize=(10, 8))\n        plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.6)\n        plt.scatter(new_centroids[:, 0], new_centroids[:, 1], \n                    c='red', marker='X', s=200, label='Centroids')\n        plt.xlabel('Bill Length (mm)')\n        plt.ylabel('Flipper Length (mm)')\n        plt.title(f'Custom K-Means Iteration {i+1}')\n        plt.legend()\n        plt.show()\n\n        if has_converged(centroids, new_centroids):\n            break\n        centroids = new_centroids\n    return labels, centroids\n\n\n\n\nRun Custom K-Means\n\n# Set number of clusters\nk = 3\n\n# Apply custom K-Means\ncustom_labels, custom_centroids = kmeans_custom(X, k)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompare with Built-in KMeans\n\n# Fit built-in KMeans\nkmeans = KMeans(n_clusters=k, random_state=42)\nbuiltin_labels = kmeans.fit_predict(X)\n\n# Plot comparison\nplt.figure(figsize=(10, 8))\nplt.scatter(X[:, 0], X[:, 1], c=builtin_labels, cmap='viridis', alpha=0.6)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n            c='red', marker='X', s=200, label='Centroids')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Flipper Length (mm)')\nplt.title('Built-in KMeans Result')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\ntodo: Calculate both the within-cluster-sum-of-squares and silhouette scores (you can use built-in functions to do so) and plot the results for various numbers of clusters (ie, K=2,3,…,7). What is the “right” number of clusters as suggested by these two metrics?\nIf you want a challenge, add your plots as an animated gif on your website so that the result looks something like this."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#optimal-number-of-clusters",
    "href": "projects/HW4/hw4_questions.html#optimal-number-of-clusters",
    "title": "Machine Learning Applications in Marketing",
    "section": "Optimal Number of Clusters",
    "text": "Optimal Number of Clusters\nWe evaluate clustering quality using:\n\nWithin-Cluster Sum of Squares (WCSS): Measures compactness (lower is better).\nSilhouette Score: Measures cohesion vs. separation (higher is better).\n\n\nfrom sklearn.metrics import silhouette_score\n\nwcss = []\nsilhouette_scores = []\nK_range = range(2, 8)\n\nfor k in K_range:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    labels = kmeans.fit_predict(X)\n    \n    # Inertia: sum of squared distances to closest cluster center\n    wcss.append(kmeans.inertia_)\n    \n    # Silhouette score\n    sil_score = silhouette_score(X, labels)\n    silhouette_scores.append(sil_score)\n\n\nPlot Both Metrics\n\nplt.figure(figsize=(10, 8))\n\n# WCSS plot\nplt.subplot(2, 1, 1)\nplt.plot(K_range, wcss, marker='o')\nplt.xlabel(\"Number of Clusters (K)\")\nplt.ylabel(\"WCSS (Inertia)\")\nplt.title(\"Elbow Method: WCSS vs. K\")\n\n# Silhouette Score plot\nplt.subplot(2, 1, 2)\nplt.plot(K_range, silhouette_scores, marker='o', color='green')\nplt.xlabel(\"Number of Clusters (K)\")\nplt.ylabel(\"Silhouette Score\")\nplt.title(\"Silhouette Score vs. K\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nAfter generating the plots: - Look for the “elbow” point in the WCSS plot. - Identify the maximum silhouette score in the second plot.\nThese together suggest the best k."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#animated-gif-of-clustering-for-k-2-to-7",
    "href": "projects/HW4/hw4_questions.html#animated-gif-of-clustering-for-k-2-to-7",
    "title": "Machine Learning Applications in Marketing",
    "section": "Animated GIF of Clustering for K = 2 to 7",
    "text": "Animated GIF of Clustering for K = 2 to 7\nWe visualize how K-Means clustering looks for different values of K, saving frames and combining them into an animated GIF.\n\nimport os\nimport imageio.v2 as imageio\n\n# Create output folder if needed\ngif_dir = \"gif_frames\"\nos.makedirs(gif_dir, exist_ok=True)\n\nfilenames = []\n\n# Generate plots for K=2 to 7\nfor k in range(2, 8):\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    labels = kmeans.fit_predict(X)\n    \n    # Plot\n    plt.figure(figsize=(8, 6))\n    plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='tab10', alpha=0.6)\n    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n                c='red', s=100, marker='X', label='Centroids')\n    plt.xlabel(\"Bill Length (mm)\")\n    plt.ylabel(\"Flipper Length (mm)\")\n    plt.title(f\"K-Means Clustering (K = {k})\")\n    plt.legend()\n    \n    # Save frame\n    filename = f\"{gif_dir}/kmeans_k{k}.png\"\n    plt.savefig(filename)\n    filenames.append(filename)\n    plt.close()\n\n\nConvert Frames to Animated GIF\n\n# Create GIF\ngif_path = \"kmeans_animation.gif\"\nwith imageio.get_writer(gif_path, mode='I', duration=1) as writer:\n    for filename in filenames:\n        image = imageio.imread(filename)\n        writer.append_data(image)\n\n# Clean up (optional)\n# for f in filenames:\n#     os.remove(f)\n\n\n\nDisplay the GIF\n\nfrom IPython.display import Image\nImage(filename=gif_path)\n\n&lt;IPython.core.display.Image object&gt;"
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#b.-latent-class-mnl",
    "href": "projects/HW4/hw4_questions.html#b.-latent-class-mnl",
    "title": "Machine Learning Applications in Marketing",
    "section": "1b. Latent-Class MNL",
    "text": "1b. Latent-Class MNL\n\nimport pandas as pd\n\n# Load the yogurt dataset\nyogurt = pd.read_csv(\"yogurt_data.csv\")\nyogurt.head()\n\n\n\n\n\n\n\n\nid\ny1\ny2\ny3\ny4\nf1\nf2\nf3\nf4\np1\np2\np3\np4\n\n\n\n\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0.108\n0.081\n0.061\n0.079\n\n\n1\n2\n0\n1\n0\n0\n0\n0\n0\n0\n0.108\n0.098\n0.064\n0.075\n\n\n2\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0.108\n0.098\n0.061\n0.086\n\n\n3\n4\n0\n1\n0\n0\n0\n0\n0\n0\n0.108\n0.098\n0.061\n0.086\n\n\n4\n5\n0\n1\n0\n0\n0\n0\n0\n0\n0.125\n0.098\n0.049\n0.079\n\n\n\n\n\n\n\n\nStep 2: Reshape to Long Format (Updated for pandas 3.12+)\n\n# Prepare long-format records in a list\nlong_rows = []\n\n# Collect rows efficiently\nfor i, row in yogurt.iterrows():\n    for j in range(1, 5):  # Alternatives 1 to 4\n        long_rows.append({\n            'id': row['id'],\n            'choice': 1 if row[f'y{j}'] == 1 else 0,\n            'alt': j,\n            'feature': row[f'f{j}'],\n            'price': row[f'p{j}']\n        })\n\n# Create DataFrame from list\nlong_df = pd.DataFrame(long_rows)\n\n# Sort and set types\nlong_df['id'] = long_df['id'].astype(int)\nlong_df['alt'] = long_df['alt'].astype(int)\nlong_df = long_df.sort_values(by=['id', 'alt'])\n\n# Preview\nlong_df.head(10)\n\n\n\n\n\n\n\n\nid\nchoice\nalt\nfeature\nprice\n\n\n\n\n0\n1\n0\n1\n0.0\n0.108\n\n\n1\n1\n0\n2\n0.0\n0.081\n\n\n2\n1\n0\n3\n0.0\n0.061\n\n\n3\n1\n1\n4\n0.0\n0.079\n\n\n4\n2\n0\n1\n0.0\n0.108\n\n\n5\n2\n1\n2\n0.0\n0.098\n\n\n6\n2\n0\n3\n0.0\n0.064\n\n\n7\n2\n0\n4\n0.0\n0.075\n\n\n8\n3\n0\n1\n0.0\n0.108\n\n\n9\n3\n1\n2\n0.0\n0.098\n\n\n\n\n\n\n\n\n\nStep 1: Load and Prepare the Yogurt Data\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.discrete.discrete_model import MNLogit\n\n# Load yogurt data\nyogurt = pd.read_csv(\"yogurt_data.csv\")\n\n# Reshape to long format\nlong_rows = []\nfor _, row in yogurt.iterrows():\n    for j in range(1, 5):\n        long_rows.append({\n            'id': row['id'],\n            'choice': 1 if row[f'y{j}'] == 1 else 0,\n            'alt': j,\n            'feature': row[f'f{j}'],\n            'price': row[f'p{j}']\n        })\nlong_df = pd.DataFrame(long_rows)\nlong_df['id'] = long_df['id'].astype(int)\nlong_df['alt'] = long_df['alt'].astype(int)\nlong_df['feature_price'] = long_df['feature'] * long_df['price']\nlong_df = long_df.sort_values(by=['id', 'alt'])\n\n\n\nStep 2: Fit the Standard MNL\n\n# Construct standard X and y\nX = long_df[['feature', 'price', 'feature_price']]\nX = sm.add_constant(X, prepend=True)\ny = long_df['choice']\n\nalt_dummies = pd.get_dummies(long_df['alt'], prefix='alt', drop_first=True)\nfor col in ['alt_2', 'alt_3', 'alt_4']:\n    if col not in alt_dummies.columns:\n        alt_dummies[col] = 0\n\nX_full = pd.concat([X.reset_index(drop=True), alt_dummies.reset_index(drop=True)], axis=1).astype(float)\ny = y.reset_index(drop=True).astype(int)\n\n# Fit MNL\nstandard_model = MNLogit(y, X_full)\nstandard_result = standard_model.fit(disp=True)\nstandard_result.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.477834\n         Iterations 8\n\n\n\nMNLogit Regression Results\n\n\nDep. Variable:\nchoice\nNo. Observations:\n9720\n\n\nModel:\nMNLogit\nDf Residuals:\n9713\n\n\nMethod:\nMLE\nDf Model:\n6\n\n\nDate:\nThu, 05 Jun 2025\nPseudo R-squ.:\n0.1503\n\n\nTime:\n13:51:55\nLog-Likelihood:\n-4644.5\n\n\nconverged:\nTrue\nLL-Null:\n-5465.9\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.000\n\n\n\n\n\n\n\n\nchoice=1\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.6273\n0.232\n11.318\n0.000\n2.172\n3.082\n\n\nfeature\n1.0609\n0.378\n2.809\n0.005\n0.321\n1.801\n\n\nprice\n-31.1935\n2.133\n-14.627\n0.000\n-35.373\n-27.014\n\n\nfeature_price\n-7.6905\n4.710\n-1.633\n0.103\n-16.923\n1.542\n\n\nalt_2\n-0.5100\n0.081\n-6.285\n0.000\n-0.669\n-0.351\n\n\nalt_3\n-4.5580\n0.173\n-26.290\n0.000\n-4.898\n-4.218\n\n\nalt_4\n-1.4102\n0.088\n-15.946\n0.000\n-1.583\n-1.237\n\n\n\n\n\n\n\nStep 3: Helper to Initialize Diverse Class Assignments\n\ndef initialize_assignments(ids, n_classes, min_size=10):\n    while True:\n        assignments = np.random.choice(n_classes, len(ids))\n        counts = np.bincount(assignments, minlength=n_classes)\n        if np.all(counts &gt;= min_size):\n            return assignments\n\n\n\nStep 4: Fit Latent-Class MNL (Improved EM)\n\ndef fit_latent_class_mnl(data, n_classes=2, n_iter=10):\n    data = data.copy()\n    ids = data['id'].unique()\n    assignments = initialize_assignments(ids, n_classes)\n\n    for iteration in range(n_iter):\n        models = []\n        for k in range(n_classes):\n            selected_ids = ids[assignments == k]\n            df_k = data[data['id'].isin(selected_ids)].copy()\n\n            if df_k.empty:\n                models.append(None)\n                continue\n\n            X_k = df_k[['feature', 'price', 'feature_price']]\n            X_k = sm.add_constant(X_k, prepend=True)\n            y_k = df_k['choice']\n            alt_dummies_k = pd.get_dummies(df_k['alt'], prefix='alt', drop_first=True)\n            for col in ['alt_2', 'alt_3', 'alt_4']:\n                if col not in alt_dummies_k.columns:\n                    alt_dummies_k[col] = 0\n            X_k_full = pd.concat([X_k.reset_index(drop=True), alt_dummies_k.reset_index(drop=True)], axis=1).astype(float)\n            y_k = y_k.reset_index(drop=True).astype(int)\n\n            try:\n                model = MNLogit(y_k, X_k_full).fit(disp=False)\n                models.append(model)\n            except Exception as e:\n                print(f\"Class {k} failed at iteration {iteration}: {e}\")\n                models.append(None)\n\n        # Reassign individuals to classes\n        new_assignments = []\n        for uid in ids:\n            person_data = data[data['id'] == uid].copy()\n            X_p = person_data[['feature', 'price', 'feature_price']]\n            X_p = sm.add_constant(X_p, prepend=True)\n            alt_dummies_p = pd.get_dummies(person_data['alt'], prefix='alt', drop_first=True)\n            for col in ['alt_2', 'alt_3', 'alt_4']:\n                if col not in alt_dummies_p.columns:\n                    alt_dummies_p[col] = 0\n            X_p_full = pd.concat([X_p.reset_index(drop=True), alt_dummies_p.reset_index(drop=True)], axis=1).astype(float)\n\n            scores = []\n            for model in models:\n                if model is None:\n                    scores.append(-np.inf)\n                    continue\n                try:\n                    ll = model.model.loglikeobs(model.params, exog=X_p_full).sum()\n                    scores.append(ll)\n                except:\n                    scores.append(-np.inf)\n\n            # Tie-breaking fix\n            if all([s == scores[0] for s in scores]) or all([s == -np.inf for s in scores]):\n                new_assignments.append(np.random.randint(0, n_classes))\n            else:\n                new_assignments.append(np.argmax(scores))\n\n        assignments = np.array(new_assignments)\n        print(f\"Iteration {iteration+1} — Class sizes: {np.bincount(assignments)}\")\n    return models\n\n\n\nStep 5: Run Models for K = 2 to 5\n\nlatent_class_results = {}\nfor k in range(2, 6):\n    print(f\"\\nFitting Latent Class MNL with {k} classes...\")\n    latent_class_results[k] = fit_latent_class_mnl(long_df, n_classes=k)\n\n\nFitting Latent Class MNL with 2 classes...\nIteration 1 — Class sizes: [1211 1219]\nIteration 2 — Class sizes: [1220 1210]\nIteration 3 — Class sizes: [1200 1230]\nIteration 4 — Class sizes: [1212 1218]\nIteration 5 — Class sizes: [1234 1196]\nIteration 6 — Class sizes: [1268 1162]\nIteration 7 — Class sizes: [1165 1265]\nIteration 8 — Class sizes: [1176 1254]\nIteration 9 — Class sizes: [1238 1192]\nIteration 10 — Class sizes: [1197 1233]\n\nFitting Latent Class MNL with 3 classes...\nIteration 1 — Class sizes: [798 850 782]\nIteration 2 — Class sizes: [831 807 792]\nIteration 3 — Class sizes: [776 782 872]\nIteration 4 — Class sizes: [862 796 772]\nIteration 5 — Class sizes: [874 747 809]\nIteration 6 — Class sizes: [796 806 828]\nIteration 7 — Class sizes: [786 779 865]\nIteration 8 — Class sizes: [809 834 787]\nIteration 9 — Class sizes: [800 811 819]\nIteration 10 — Class sizes: [772 858 800]\n\nFitting Latent Class MNL with 4 classes...\nIteration 1 — Class sizes: [597 653 584 596]\nIteration 2 — Class sizes: [571 609 619 631]\nIteration 3 — Class sizes: [622 623 619 566]\nIteration 4 — Class sizes: [585 616 589 640]\nIteration 5 — Class sizes: [613 592 590 635]\nIteration 6 — Class sizes: [628 614 606 582]\nIteration 7 — Class sizes: [598 607 643 582]\nIteration 8 — Class sizes: [631 587 610 602]\nIteration 9 — Class sizes: [607 632 608 583]\nIteration 10 — Class sizes: [607 626 594 603]\n\nFitting Latent Class MNL with 5 classes...\nIteration 1 — Class sizes: [514 485 485 465 481]\nIteration 2 — Class sizes: [468 482 515 499 466]\nIteration 3 — Class sizes: [511 456 473 527 463]\nIteration 4 — Class sizes: [493 501 455 509 472]\nIteration 5 — Class sizes: [497 488 465 496 484]\nIteration 6 — Class sizes: [481 501 501 447 500]\nIteration 7 — Class sizes: [464 497 486 512 471]\nIteration 8 — Class sizes: [481 504 463 490 492]\nIteration 9 — Class sizes: [473 511 455 483 508]\nIteration 10 — Class sizes: [494 502 482 469 483]\n\n\n\n\nStep 6: Summarize Log-Likelihoods\n\nloglik_summary = {\n    k: [round(m.llf, 2) if m else None for m in models]\n    for k, models in latent_class_results.items()\n}\nloglik_summary\n\n{2: [-2374.39, -2269.7],\n 3: [-1533.36, -1564.03, -1540.3],\n 4: [-1164.11, -1177.15, -1170.96, -1115.39],\n 5: [-893.24, -955.91, -897.52, -893.59, -991.23]}"
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#b.-latent-class-multinomial-logit-lc-mnl-yogurt-dataset",
    "href": "projects/HW4/hw4_questions.html#b.-latent-class-multinomial-logit-lc-mnl-yogurt-dataset",
    "title": "Machine Learning Applications in Marketing",
    "section": "1b. Latent-Class Multinomial Logit (LC-MNL) – Yogurt Dataset",
    "text": "1b. Latent-Class Multinomial Logit (LC-MNL) – Yogurt Dataset\n\nimport pandas as pd\n\n# Load the yogurt dataset\nyogurt = pd.read_csv(\"yogurt_data.csv\")\nyogurt.head()\n\n\n\n\n\n\n\n\nid\ny1\ny2\ny3\ny4\nf1\nf2\nf3\nf4\np1\np2\np3\np4\n\n\n\n\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0.108\n0.081\n0.061\n0.079\n\n\n1\n2\n0\n1\n0\n0\n0\n0\n0\n0\n0.108\n0.098\n0.064\n0.075\n\n\n2\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0.108\n0.098\n0.061\n0.086\n\n\n3\n4\n0\n1\n0\n0\n0\n0\n0\n0\n0.108\n0.098\n0.061\n0.086\n\n\n4\n5\n0\n1\n0\n0\n0\n0\n0\n0\n0.125\n0.098\n0.049\n0.079\n\n\n\n\n\n\n\n\n\n🔹 Step 2: Reshape to Long Format (Updated for pandas 3.12+)\n\n# Prepare long-format records in a list\nlong_rows = []\n\n# Collect rows efficiently\nfor i, row in yogurt.iterrows():\n    for j in range(1, 5):  # Alternatives 1 to 4\n        long_rows.append({\n            'id': row['id'],\n            'choice': 1 if row[f'y{j}'] == 1 else 0,\n            'alt': j,\n            'feature': row[f'f{j}'],\n            'price': row[f'p{j}']\n        })\n\n# Create DataFrame from list\nlong_df = pd.DataFrame(long_rows)\n\n# Sort and set types\nlong_df['id'] = long_df['id'].astype(int)\nlong_df['alt'] = long_df['alt'].astype(int)\nlong_df = long_df.sort_values(by=['id', 'alt'])\n\n# Preview\nlong_df.head(10)\n\n\n\n\n\n\n\n\nid\nchoice\nalt\nfeature\nprice\n\n\n\n\n0\n1\n0\n1\n0.0\n0.108\n\n\n1\n1\n0\n2\n0.0\n0.081\n\n\n2\n1\n0\n3\n0.0\n0.061\n\n\n3\n1\n1\n4\n0.0\n0.079\n\n\n4\n2\n0\n1\n0.0\n0.108\n\n\n5\n2\n1\n2\n0.0\n0.098\n\n\n6\n2\n0\n3\n0.0\n0.064\n\n\n7\n2\n0\n4\n0.0\n0.075\n\n\n8\n3\n0\n1\n0.0\n0.108\n\n\n9\n3\n1\n2\n0.0\n0.098\n\n\n\n\n\n\n\ntodo: Fit the standard MNL model on these data. Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes.\n\n\nStep 1: Load and Prepare the Yogurt Data\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.discrete.discrete_model import MNLogit\n\n# Load yogurt data\nyogurt = pd.read_csv(\"yogurt_data.csv\")\n\n# Reshape to long format\nlong_rows = []\nfor _, row in yogurt.iterrows():\n    for j in range(1, 5):\n        long_rows.append({\n            'id': row['id'],\n            'choice': 1 if row[f'y{j}'] == 1 else 0,\n            'alt': j,\n            'feature': row[f'f{j}'],\n            'price': row[f'p{j}']\n        })\nlong_df = pd.DataFrame(long_rows)\nlong_df['id'] = long_df['id'].astype(int)\nlong_df['alt'] = long_df['alt'].astype(int)\nlong_df['feature_price'] = long_df['feature'] * long_df['price']\nlong_df = long_df.sort_values(by=['id', 'alt'])\n\n\n\n\nStep 2: Fit the Standard MNL\n\n# Construct standard X and y\nX = long_df[['feature', 'price', 'feature_price']]\nX = sm.add_constant(X, prepend=True)\ny = long_df['choice']\n\nalt_dummies = pd.get_dummies(long_df['alt'], prefix='alt', drop_first=True)\nfor col in ['alt_2', 'alt_3', 'alt_4']:\n    if col not in alt_dummies.columns:\n        alt_dummies[col] = 0\n\nX_full = pd.concat([X.reset_index(drop=True), alt_dummies.reset_index(drop=True)], axis=1).astype(float)\ny = y.reset_index(drop=True).astype(int)\n\n# Fit MNL\nstandard_model = MNLogit(y, X_full)\nstandard_result = standard_model.fit(disp=True)\nstandard_result.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.477834\n         Iterations 8\n\n\n\nMNLogit Regression Results\n\n\nDep. Variable:\nchoice\nNo. Observations:\n9720\n\n\nModel:\nMNLogit\nDf Residuals:\n9713\n\n\nMethod:\nMLE\nDf Model:\n6\n\n\nDate:\nThu, 05 Jun 2025\nPseudo R-squ.:\n0.1503\n\n\nTime:\n13:44:15\nLog-Likelihood:\n-4644.5\n\n\nconverged:\nTrue\nLL-Null:\n-5465.9\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.000\n\n\n\n\n\n\n\n\nchoice=1\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.6273\n0.232\n11.318\n0.000\n2.172\n3.082\n\n\nfeature\n1.0609\n0.378\n2.809\n0.005\n0.321\n1.801\n\n\nprice\n-31.1935\n2.133\n-14.627\n0.000\n-35.373\n-27.014\n\n\nfeature_price\n-7.6905\n4.710\n-1.633\n0.103\n-16.923\n1.542\n\n\nalt_2\n-0.5100\n0.081\n-6.285\n0.000\n-0.669\n-0.351\n\n\nalt_3\n-4.5580\n0.173\n-26.290\n0.000\n-4.898\n-4.218\n\n\nalt_4\n-1.4102\n0.088\n-15.946\n0.000\n-1.583\n-1.237\n\n\n\n\n\n\n\n\nStep 3: Helper to Initialize Diverse Class Assignments\n\ndef initialize_assignments(ids, n_classes, min_size=10):\n    while True:\n        assignments = np.random.choice(n_classes, len(ids))\n        counts = np.bincount(assignments, minlength=n_classes)\n        if np.all(counts &gt;= min_size):\n            return assignments\n\n\n\n\nStep 4: Fit Latent-Class MNL (Improved EM)\n\ndef fit_latent_class_mnl(data, n_classes=2, n_iter=10):\n    data = data.copy()\n    ids = data['id'].unique()\n    assignments = initialize_assignments(ids, n_classes)\n\n    for iteration in range(n_iter):\n        models = []\n        for k in range(n_classes):\n            selected_ids = ids[assignments == k]\n            df_k = data[data['id'].isin(selected_ids)].copy()\n\n            if df_k.empty:\n                models.append(None)\n                continue\n\n            X_k = df_k[['feature', 'price', 'feature_price']]\n            X_k = sm.add_constant(X_k, prepend=True)\n            y_k = df_k['choice']\n            alt_dummies_k = pd.get_dummies(df_k['alt'], prefix='alt', drop_first=True)\n            for col in ['alt_2', 'alt_3', 'alt_4']:\n                if col not in alt_dummies_k.columns:\n                    alt_dummies_k[col] = 0\n            X_k_full = pd.concat([X_k.reset_index(drop=True), alt_dummies_k.reset_index(drop=True)], axis=1).astype(float)\n            y_k = y_k.reset_index(drop=True).astype(int)\n\n            try:\n                model = MNLogit(y_k, X_k_full).fit(disp=False)\n                models.append(model)\n            except Exception as e:\n                print(f\"Class {k} failed at iteration {iteration}: {e}\")\n                models.append(None)\n\n        # Reassign individuals to classes\n        new_assignments = []\n        for uid in ids:\n            person_data = data[data['id'] == uid].copy()\n            X_p = person_data[['feature', 'price', 'feature_price']]\n            X_p = sm.add_constant(X_p, prepend=True)\n            alt_dummies_p = pd.get_dummies(person_data['alt'], prefix='alt', drop_first=True)\n            for col in ['alt_2', 'alt_3', 'alt_4']:\n                if col not in alt_dummies_p.columns:\n                    alt_dummies_p[col] = 0\n            X_p_full = pd.concat([X_p.reset_index(drop=True), alt_dummies_p.reset_index(drop=True)], axis=1).astype(float)\n\n            scores = []\n            for model in models:\n                if model is None:\n                    scores.append(-np.inf)\n                    continue\n                try:\n                    ll = model.model.loglikeobs(model.params, exog=X_p_full).sum()\n                    scores.append(ll)\n                except:\n                    scores.append(-np.inf)\n\n            # Tie-breaking fix\n            if all([s == scores[0] for s in scores]) or all([s == -np.inf for s in scores]):\n                new_assignments.append(np.random.randint(0, n_classes))\n            else:\n                new_assignments.append(np.argmax(scores))\n\n        assignments = np.array(new_assignments)\n        print(f\"Iteration {iteration+1} — Class sizes: {np.bincount(assignments)}\")\n    return models\n\n\n\n\nStep 5: Run Models for K = 2 to 5\n\nlatent_class_results = {}\nfor k in range(2, 6):\n    print(f\"\\nFitting Latent Class MNL with {k} classes...\")\n    latent_class_results[k] = fit_latent_class_mnl(long_df, n_classes=k)\n\n\nFitting Latent Class MNL with 2 classes...\nIteration 1 — Class sizes: [1211 1219]\nIteration 2 — Class sizes: [1220 1210]\nIteration 3 — Class sizes: [1200 1230]\nIteration 4 — Class sizes: [1212 1218]\nIteration 5 — Class sizes: [1234 1196]\nIteration 6 — Class sizes: [1268 1162]\nIteration 7 — Class sizes: [1165 1265]\nIteration 8 — Class sizes: [1176 1254]\nIteration 9 — Class sizes: [1238 1192]\nIteration 10 — Class sizes: [1197 1233]\n\nFitting Latent Class MNL with 3 classes...\nIteration 1 — Class sizes: [798 850 782]\nIteration 2 — Class sizes: [831 807 792]\nIteration 3 — Class sizes: [776 782 872]\nIteration 4 — Class sizes: [862 796 772]\nIteration 5 — Class sizes: [874 747 809]\nIteration 6 — Class sizes: [796 806 828]\nIteration 7 — Class sizes: [786 779 865]\nIteration 8 — Class sizes: [809 834 787]\nIteration 9 — Class sizes: [800 811 819]\nIteration 10 — Class sizes: [772 858 800]\n\nFitting Latent Class MNL with 4 classes...\nIteration 1 — Class sizes: [597 653 584 596]\nIteration 2 — Class sizes: [571 609 619 631]\nIteration 3 — Class sizes: [622 623 619 566]\nIteration 4 — Class sizes: [585 616 589 640]\nIteration 5 — Class sizes: [613 592 590 635]\nIteration 6 — Class sizes: [628 614 606 582]\nIteration 7 — Class sizes: [598 607 643 582]\nIteration 8 — Class sizes: [631 587 610 602]\nIteration 9 — Class sizes: [607 632 608 583]\nIteration 10 — Class sizes: [607 626 594 603]\n\nFitting Latent Class MNL with 5 classes...\nIteration 1 — Class sizes: [514 485 485 465 481]\nIteration 2 — Class sizes: [468 482 515 499 466]\nIteration 3 — Class sizes: [511 456 473 527 463]\nIteration 4 — Class sizes: [493 501 455 509 472]\nIteration 5 — Class sizes: [497 488 465 496 484]\nIteration 6 — Class sizes: [481 501 501 447 500]\nIteration 7 — Class sizes: [464 497 486 512 471]\nIteration 8 — Class sizes: [481 504 463 490 492]\nIteration 9 — Class sizes: [473 511 455 483 508]\nIteration 10 — Class sizes: [494 502 482 469 483]\n\n\n\n\n\nStep 6: Summarize Log-Likelihoods\n\nloglik_summary = {\n    k: [round(m.llf, 2) if m else None for m in models]\n    for k, models in latent_class_results.items()\n}\nloglik_summary\n\n{2: [-2374.39, -2269.7],\n 3: [-1533.36, -1564.03, -1540.3],\n 4: [-1164.11, -1177.15, -1170.96, -1115.39],\n 5: [-893.24, -955.91, -897.52, -893.59, -991.23]}\n\n\ntodo: How many classes are suggested by the \\(BIC = -2*\\ell_n  + k*log(n)\\)? (where \\(\\ell_n\\) is the log-likelihood, \\(n\\) is the sample size, and \\(k\\) is the number of parameters.) The Bayesian-Schwarz Information Criterion link is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate – akin to the adjusted R-squared for the linear regression model. Note, that a lower BIC indicates a better model fit, accounting for the number of parameters in the model."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#model-selection-via-bic",
    "href": "projects/HW4/hw4_questions.html#model-selection-via-bic",
    "title": "Machine Learning Applications in Marketing",
    "section": "Model Selection via BIC",
    "text": "Model Selection via BIC\nTo determine the optimal number of latent classes in the MNL model, we compute the Bayesian Information Criterion (BIC) for each specification using the formula:\n[ = -2 _n + k (n) ]\nWhere: - (_n) is the total log-likelihood from all class-specific models - (k) is the total number of estimated parameters across classes (7 per class) - (n) is the number of choice observations\nBased on the estimated log-likelihoods:\n\n\n\nNumber of Classes\nBIC Score\n\n\n\n\n2\n9412.37\n\n\n3\n9470.06\n\n\n4\n9530.61\n\n\n5\n9580.41\n\n\n\nWe observe that the BIC is minimized at 2 classes, suggesting that a 2-class latent-class MNL model provides the best balance between model fit and complexity.\n\nInterpretation\nThe result implies that the yogurt purchase data likely consists of two distinct consumer segments, each with different sensitivities to price, promotions (feature ads), or product alternatives. Adding more latent classes increases model complexity without sufficient improvement in fit, as reflected in the rising BIC values. Therefore, the 2-class model captures meaningful heterogeneity in consumer choice behavior without overfitting.\nConclusion:\n&gt; The optimal number of classes based on BIC is 2, indicating two meaningful latent consumer segments."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#parameter-comparison-aggregate-vs.-latent-class-mnl",
    "href": "projects/HW4/hw4_questions.html#parameter-comparison-aggregate-vs.-latent-class-mnl",
    "title": "Machine Learning Applications in Marketing",
    "section": "Parameter Comparison: Aggregate vs. Latent-Class MNL",
    "text": "Parameter Comparison: Aggregate vs. Latent-Class MNL\nAfter identifying the 2-class latent-class MNL model as the best fit via BIC, we now compare the estimated parameters from:\n\nThe aggregate MNL (which assumes homogeneous preferences), and\n\nThe latent-class MNL with 2 classes (which allows for preference heterogeneity).\n\nThis comparison helps reveal potential variation in preferences across unobserved consumer segments.\n\nParameter Estimates\n\n\n\nParameter\nAggregate MNL\nClass 1\nClass 2\n\n\n\n\nIntercept\n2.6273\n2.5159\n2.7684\n\n\nFeature\n1.0609\n1.4041\n0.7342\n\n\nPrice\n-31.1935\n-29.5258\n-33.1863\n\n\nFeature × Price\n-7.6905\n-12.7906\n-2.8699\n\n\nalt_2\n-0.5100\n-0.5771\n-0.4441\n\n\nalt_3\n-4.5580\n-4.6437\n-4.4916\n\n\nalt_4\n-1.4102\n-1.4441\n-1.3793\n\n\n\n\n\n\nInterpretation\n\nIntercept terms are similar across models, reflecting baseline preference levels.\nThe feature (promotion) effect is highest for Class 1 (1.4041), suggesting stronger responsiveness to promotions. In contrast, Class 2 (0.7342) is less influenced by promotional cues.\nPrice sensitivity is negative for all models, as expected. Class 2 has the most negative value (−33.19), indicating the highest price sensitivity.\nThe feature × price interaction shows notable heterogeneity:\n\nClass 1: −12.79 → stronger negative interaction, possibly indicating diminishing returns to promotion as price increases.\nClass 2: −2.87 → smaller effect, suggesting more stable response to price under promotion.\n\nThe alternative-specific constants are consistently negative, with slight variation, capturing unobserved preferences between product options.\n\n\n\nConclusion\n\nThe latent-class MNL reveals two consumer segments: - Class 1: More responsive to promotions, but with moderate price sensitivity. - Class 2: Less influenced by promotions but highly price-sensitive.\n\nThis segmentation provides actionable insight for pricing and promotion strategies, which would be masked in the aggregate model."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#a.-k-nearest-neighbors",
    "href": "projects/HW4/hw4_questions.html#a.-k-nearest-neighbors",
    "title": "Machine Learning Applications in Marketing",
    "section": "2a. K Nearest Neighbors",
    "text": "2a. K Nearest Neighbors\nWe implement the KNN algorithm from scratch and apply it to the data_for_drivers_analysis.csv dataset to predict customer satisfaction using key driver variables.\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom collections import Counter\n\n# Load the dataset\ndf = pd.read_csv(\"data_for_drivers_analysis.csv\")\n\n# Select features and target\nfeatures = ['trust', 'build', 'differs', 'easy', 'appealing', 'rewarding', 'popular', 'service', 'impact']\nX = df[features]\ny = df['satisfaction']\n\n# Normalize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split into train/test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n\n\nManual KNN Classifier\n\n# Euclidean distance function\ndef euclidean_distance(x1, x2):\n    return np.sqrt(np.sum((x1 - x2) ** 2))\n\n# Manual KNN implementation\nclass KNN:\n    def __init__(self, k=5):\n        self.k = k\n\n    def fit(self, X_train, y_train):\n        self.X_train = np.array(X_train)\n        self.y_train = np.array(y_train)\n\n    def predict(self, X_test):\n        return [self._predict(x) for x in X_test]\n\n    def _predict(self, x):\n        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n        k_indices = np.argsort(distances)[:self.k]\n        k_nearest_labels = self.y_train[k_indices]\n        return Counter(k_nearest_labels).most_common(1)[0][0]\n\n\n\nEvaluate on the Test Set\n\n# Train and evaluate the model\nknn = KNN(k=5)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\naccuracy = np.mean(predictions == y_test)\nprint(f\"Test Accuracy: {accuracy:.3f}\")\n\nTest Accuracy: 0.285\n\n\n\n\nNotes\n\nThis is a multiclass KNN classifier predicting satisfaction scores from 1 to 5.\nAccuracy may appear modest (e.g., ~28%) due to class imbalance or ordinal target.\nYou may optionally convert satisfaction to binary (e.g., high vs. low) or tune k.\n\n\n\nCheck: Compare with sklearn KNN\nWe now compare our manual KNN implementation to sklearn.neighbors.KNeighborsClassifier using the same data and k.\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Fit sklearn model\nsk_model = KNeighborsClassifier(n_neighbors=5)\nsk_model.fit(X_train, y_train)\nsk_predictions = sk_model.predict(X_test)\n\n# Compare accuracy\nsk_accuracy = np.mean(sk_predictions == y_test)\nprint(f\"Sklearn KNN Accuracy: {sk_accuracy:.3f}\")\n\nSklearn KNN Accuracy: 0.316\n\n\n\n\nInterpretation\n\n\nComparison with sklearn KNN\nTo validate our hand-coded KNN implementation, we compare it to the KNeighborsClassifier from sklearn using the same data, features, and k = 5.\nResults:\n\n\n\nModel\nAccuracy\n\n\n\n\nManual KNN\n0.285\n\n\nsklearn KNN\n0.316\n\n\n\n\n\nInterpretation\n\nThe accuracy from our manual KNN (28.5%) is very close to that of sklearn’s KNN (31.6%), indicating that the custom implementation is functioning correctly.\nThe small difference is likely due to implementation-level optimizations in sklearn, such as:\n\nMore efficient tie-breaking logic\nOptimized numerical stability\n\nThis confirms that our model correctly performs KNN classification from first principles on a real-world dataset.\n\nConclusion:\n&gt; Our KNN implementation behaves as expected and generalizes similarly to the sklearn version on the test data."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#a.-k-nearest-neighbors-knn-by-hand",
    "href": "projects/HW4/hw4_questions.html#a.-k-nearest-neighbors-knn-by-hand",
    "title": "Machine Learning Applications in Marketing",
    "section": "2a. K Nearest Neighbors (KNN by Hand)",
    "text": "2a. K Nearest Neighbors (KNN by Hand)\nWe implement the KNN algorithm from scratch and apply it to the data_for_drivers_analysis.csv dataset to predict customer satisfaction using key driver variables.\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom collections import Counter\n\n# Load the dataset\ndf = pd.read_csv(\"data_for_drivers_analysis.csv\")\n\n# Select features and target\nfeatures = ['trust', 'build', 'differs', 'easy', 'appealing', 'rewarding', 'popular', 'service', 'impact']\nX = df[features]\ny = df['satisfaction']\n\n# Normalize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split into train/test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n\n\n\nManual KNN Classifier\n\n# Euclidean distance function\ndef euclidean_distance(x1, x2):\n    return np.sqrt(np.sum((x1 - x2) ** 2))\n\n# Manual KNN implementation\nclass KNN:\n    def __init__(self, k=5):\n        self.k = k\n\n    def fit(self, X_train, y_train):\n        self.X_train = np.array(X_train)\n        self.y_train = np.array(y_train)\n\n    def predict(self, X_test):\n        return [self._predict(x) for x in X_test]\n\n    def _predict(self, x):\n        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n        k_indices = np.argsort(distances)[:self.k]\n        k_nearest_labels = self.y_train[k_indices]\n        return Counter(k_nearest_labels).most_common(1)[0][0]\n\n\n\n\nEvaluate on the Test Set\n\n# Train and evaluate the model\nknn = KNN(k=5)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\naccuracy = np.mean(predictions == y_test)\nprint(f\"Test Accuracy: {accuracy:.3f}\")\n\nTest Accuracy: 0.285\n\n\n\n\n\nNotes\n\nThis is a multiclass KNN classifier predicting satisfaction scores from 1 to 5.\nAccuracy may appear modest (e.g., ~28%) due to class imbalance or ordinal target.\nYou may optionally convert satisfaction to binary (e.g., high vs. low) or tune k.\n\ntodo: check your function by…\n\n\nCheck: Compare with sklearn KNN\nWe now compare our manual KNN implementation to sklearn.neighbors.KNeighborsClassifier using the same data and k.\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Fit sklearn model\nsk_model = KNeighborsClassifier(n_neighbors=5)\nsk_model.fit(X_train, y_train)\nsk_predictions = sk_model.predict(X_test)\n\n# Compare accuracy\nsk_accuracy = np.mean(sk_predictions == y_test)\nprint(f\"Sklearn KNN Accuracy: {sk_accuracy:.3f}\")\n\nSklearn KNN Accuracy: 0.316\n\n\n\n\n\nInterpretation\n\n\nComparison with sklearn KNN\nTo validate our hand-coded KNN implementation, we compare it to the KNeighborsClassifier from sklearn using the same data, features, and k = 5.\nResults:\n\n\n\nModel\nAccuracy\n\n\n\n\nManual KNN\n0.285\n\n\nsklearn KNN\n0.316\n\n\n\n\n\nInterpretation\n\nThe accuracy from our manual KNN (28.5%) is very close to that of sklearn’s KNN (31.6%), indicating that the custom implementation is functioning correctly.\nThe small difference is likely due to implementation-level optimizations in sklearn, such as:\n\nMore efficient tie-breaking logic\nOptimized numerical stability\n\nThis confirms that our model correctly performs KNN classification from first principles on a real-world dataset.\n\nConclusion:\n&gt; Our KNN implementation behaves as expected and generalizes similarly to the sklearn version on the test data."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#b.-key-drivers-analysis",
    "href": "projects/HW4/hw4_questions.html#b.-key-drivers-analysis",
    "title": "Machine Learning Applications in Marketing",
    "section": "2b. Key Drivers Analysis",
    "text": "2b. Key Drivers Analysis\nWe replicate the key driver table shown on slide 75 of Session 5, using the data_for_drivers_analysis.csv dataset. The target variable is satisfaction, and the drivers include:\n\ntrust, build, differs, easy, appealing, rewarding, popular, service, impact\n\n\nLoad and Preprocess Data\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom scipy.stats import pearsonr\n\n# Load the dataset\ndf = pd.read_csv(\"data_for_drivers_analysis.csv\")\n\n# Define target and features\ntarget = 'satisfaction'\nfeatures = ['trust', 'build', 'differs', 'easy', 'appealing', 'rewarding', 'popular', 'service', 'impact']\nX = df[features]\ny = df[target]\n\n\n\nPearson Correlation and Standardized Coefficients\n\n# Standardize features and target\nX_std = StandardScaler().fit_transform(X)\ny_std = StandardScaler().fit_transform(y.values.reshape(-1, 1)).flatten()\n\n# Pearson correlations\npearson_r = [pearsonr(X[feat], y)[0] for feat in features]\n\n# Standardized regression coefficients\nreg = LinearRegression().fit(X_std, y_std)\nstd_coef = reg.coef_\n\n\n\nUsefulness (R²) and RF Gini Importance\n\n# Usefulness: R² from single-feature linear models\nusefulness_r2 = []\nfor feat in features:\n    model = LinearRegression().fit(X[[feat]], y)\n    preds = model.predict(X[[feat]])\n    usefulness_r2.append(r2_score(y, preds))\n\n# Random Forest for Mean Decrease in Gini\nrf = RandomForestRegressor(n_estimators=100, random_state=42)\nrf.fit(X, y)\nrf_gini = rf.feature_importances_\n\n\n\nAssemble Table\n\n# Create results table\ndriver_table = pd.DataFrame({\n    'Variable': features,\n    'Pearson r': np.round(pearson_r, 3),\n    'Standardized Coef': np.round(std_coef, 3),\n    'Usefulness (R²)': np.round(usefulness_r2, 3),\n    'RF Gini': np.round(rf_gini, 3)\n})\n\n# Sort by Usefulness or Pearson by default\ndriver_table = driver_table.sort_values(\"Pearson r\", ascending=False).reset_index(drop=True)\ndriver_table\n\n\n\n\n\n\n\n\nVariable\nPearson r\nStandardized Coef\nUsefulness (R²)\nRF Gini\n\n\n\n\n0\ntrust\n0.256\n0.116\n0.065\n0.156\n\n\n1\nimpact\n0.255\n0.128\n0.065\n0.141\n\n\n2\nservice\n0.251\n0.088\n0.063\n0.130\n\n\n3\neasy\n0.213\n0.022\n0.045\n0.100\n\n\n4\nappealing\n0.208\n0.034\n0.043\n0.086\n\n\n5\nrewarding\n0.195\n0.005\n0.038\n0.101\n\n\n6\nbuild\n0.192\n0.020\n0.037\n0.102\n\n\n7\ndiffers\n0.185\n0.028\n0.034\n0.090\n\n\n8\npopular\n0.171\n0.017\n0.029\n0.095\n\n\n\n\n\n\n\n\n\nJohnson’s Relative Weights\nWe compute Johnson’s Relative Weights using a common approach based on singular value decomposition (SVD) of the correlation matrix.\n\ndef compute_johnsons_weights(X, y):\n    # Correlation matrix\n    R = np.corrcoef(np.column_stack((X, y)), rowvar=False)\n    Rxx = R[:-1, :-1]\n    Rxy = R[:-1, -1]\n\n    # Eigen decomposition\n    eigval, eigvec = np.linalg.eig(Rxx)\n    Lambda_half = np.diag(np.sqrt(eigval))\n    Z = eigvec @ Lambda_half @ eigvec.T\n    beta = np.linalg.inv(Z.T @ Z) @ Z.T @ Rxy\n\n    raw_weights = (Z @ beta) ** 2\n    rel_weights = raw_weights / raw_weights.sum()\n    return rel_weights\n\njohnson_weights = compute_johnsons_weights(X.values, y.values)\ndriver_table['Johnson\\'s RW'] = np.round(johnson_weights, 3)\n\n\n\n\nFinal Table: All Metrics Combined\n\ndriver_table = driver_table[['Variable', 'Pearson r', 'Standardized Coef', 'Usefulness (R²)', 'Johnson\\'s RW', 'RF Gini']]\ndriver_table.sort_values(\"Usefulness (R²)\", ascending=False)\n\n\n\n\n\n\n\n\nVariable\nPearson r\nStandardized Coef\nUsefulness (R²)\nJohnson's RW\nRF Gini\n\n\n\n\n0\ntrust\n0.256\n0.116\n0.065\n0.156\n0.156\n\n\n1\nimpact\n0.255\n0.128\n0.065\n0.088\n0.141\n\n\n2\nservice\n0.251\n0.088\n0.063\n0.081\n0.130\n\n\n3\neasy\n0.213\n0.022\n0.045\n0.108\n0.100\n\n\n4\nappealing\n0.208\n0.034\n0.043\n0.103\n0.086\n\n\n5\nrewarding\n0.195\n0.005\n0.038\n0.090\n0.101\n\n\n6\nbuild\n0.192\n0.020\n0.037\n0.070\n0.102\n\n\n7\ndiffers\n0.185\n0.028\n0.034\n0.150\n0.090\n\n\n8\npopular\n0.171\n0.017\n0.029\n0.154\n0.095\n\n\n\n\n\n\n\n\n\nInterpretation\n\nTop drivers across all methods include:\n\ntrust: strong Pearson, standardized beta, R², and Gini\nimpact: consistently influential across methods\nservice: ranks highly on both usefulness and correlation\n\n\nThese features appear to be most predictive of customer satisfaction, and should be prioritized for strategic focus.\n\n\nNotes\n\nMetrics are all scaled for comparability, and represent different perspectives:\n\nCorrelation = bivariate strength\nStandardized Coef = multivariate linear influence\nUsefulness = unique explained variance\nRF Gini = non-linear predictive value\n\n\n\n\n\nConclusion\n\nThe replicated table highlights that trust, impact, and service are the strongest key drivers of satisfaction in this dataset — closely matching the credit card example from Session 5."
  }
]